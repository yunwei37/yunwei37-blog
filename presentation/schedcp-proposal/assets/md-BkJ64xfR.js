import{o as a,b as i,w as r,g as e,ad as t,v as u,x as d,T as o}from"./modules/vue-CVEjzCsQ.js";import{I as c}from"./slidev/default-V9psg9Br.js";import{u as m,f as g}from"./slidev/context-fcO_mvCq.js";import"./index-D8uROvuN.js";import"./modules/shiki-vBOq2oBG.js";const b={__name:"slides.md__slidev_5",setup(h){const{$clicksContext:n,$frontmatter:s}=m();return n.setup(),(p,l)=>(a(),i(c,u(d(o(g)(o(s),4))),{default:r(()=>[...l[0]||(l[0]=[e("h1",null,"Benchmark Framework Design",-1),e("p",null,[t("Goal: Evaluate LLM agent’s ability to optimize OS behavior for diverse workloads under explicit "),e("strong",null,"SLOs"),t(" and "),e("strong",null,"budgets"),t(" (time, tokens, CPU/energy)")],-1),e("p",null,"Build a RL-like environment for the agents, and allow agents to tune the OS configs and using code generation to alert OS behavior.",-1),e("div",{class:"grid grid-cols-2 gap-4 text-sm"},[e("div",null,[e("h2",null,"RQs"),e("ul",null,[e("li",null,"Can agents infer optimization goals from telemetry, without being told the SLO?"),e("li",null,"Can they hold SLOs under drift with controller‑grade stability (no thrash)?"),e("li",null,"What improvement do we buy per token/second—what are the scaling laws?"),e("li",null,"How does agents achieve optimizations? Do we need to design better system interface?")])]),e("div",null,[e("h2",null,"Task Design (2-Phase Challenge)"),e("ol",null,[e("li",null,[e("strong",null,"Goal Inference"),t(": From traces/metrics/logs, infer bottlenecks & optimization targets")]),e("li",null,[e("strong",null,"Policy/Tool Synthesis"),t(": Select/configure tools OR synthesize code (eBPF schedulers) to meet SLOs")])]),e("p",null,"Test with different models and agents (Claude code, codex)")])],-1)])]),_:1},16))}};export{b as default};
