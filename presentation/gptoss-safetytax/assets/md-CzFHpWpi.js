import{o as d,b as n,w as g,g as t,j as r,ad as e,v as i,x as c,T as s}from"./modules/vue-CVEjzCsQ.js";import{I as u}from"./slidev/default-BqaX2aeV.js";import{u as x,f as m}from"./slidev/context-BxwITPeH.js";import"./index-CTBsFxrU.js";import"./modules/shiki-vBOq2oBG.js";const w={__name:"slides.md__slidev_3",setup(p){const{$clicksContext:o,$frontmatter:l}=x();return o.setup(),(h,a)=>(d(),n(u,i(c(s(m)(s(l),2))),{default:g(()=>[...a[0]||(a[0]=[t("h1",null,"LLM vs LRM (reasoning model)",-1),t("div",{class:"grid grid-cols-1 md:grid-cols-5 gap-8 mt-6"},[r(" LLM Card "),t("div",{class:"md:col-span-2 bg-gray-50/80 dark:bg-gray-800/80 p-6 rounded-xl shadow-lg border border-gray-200 dark:border-gray-700 backdrop-blur-sm"},[t("div",{class:"flex items-center mb-4"},[t("div",{class:"p-2 bg-blue-100 dark:bg-blue-900/50 rounded-lg mr-4"},[t("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor","stroke-width":"2","stroke-linecap":"round","stroke-linejoin":"round",class:"text-blue-500"},[t("path",{d:"M12 22c5.523 0 10-4.477 10-10S17.523 2 12 2 2 6.477 2 12s4.477 10 10 10z"}),t("path",{d:"M12 12a5 5 0 0 0 5-5"}),t("path",{d:"M12 12a5 5 0 0 1 5 5"})])]),t("h2",{class:"text-2xl font-bold text-gray-800 dark:text-gray-100"},"LLM")]),t("p",{class:"text-gray-600 dark:text-gray-300"}," Standard Large Language Models are focused on conversational ability through pre-training and alignment for chat. ")]),r(" LRM Card "),t("div",{class:"md:col-span-3 bg-gray-50/80 dark:bg-gray-800/80 p-6 rounded-xl shadow-lg border border-gray-200 dark:border-gray-700 backdrop-blur-sm"},[t("div",{class:"flex items-center mb-4"},[t("div",{class:"p-2 bg-teal-100 dark:bg-teal-900/50 rounded-lg mr-4"},[t("svg",{xmlns:"http://www.w3.org/2000/svg",width:"24",height:"24",viewBox:"0 0 24 24",fill:"none",stroke:"currentColor","stroke-width":"2","stroke-linecap":"round","stroke-linejoin":"round",class:"text-teal-500"},[t("path",{d:"M12 22c5.523 0 10-4.477 10-10S17.523 2 12 2 2 6.477 2 12s4.477 10 10 10z"}),t("path",{d:"M12 8v8"}),t("path",{d:"m8.5 14-4-4 4-4"})])]),t("h2",{class:"text-2xl font-bold text-gray-800 dark:text-gray-100"},"LRM (Reasoning Model)")]),t("ul",{class:"space-y-3 text-gray-600 dark:text-gray-300"},[t("li",null,[t("strong",{class:"font-semibold text-gray-700 dark:text-gray-200"},"Enhanced Training:"),e(" Adds "),t("strong",{class:"text-teal-600 dark:text-teal-400"},"reasoning RL"),e(" post-training to teach "),t("strong",{class:"text-teal-600 dark:text-teal-400"},"chain-of-thought"),e(" (CoT) and "),t("strong",{class:"text-teal-600 dark:text-teal-400"},"tool use"),e(".")]),t("li",null,[t("strong",{class:"font-semibold text-gray-700 dark:text-gray-200"},"Key Property:"),e(" Features "),t("strong",{class:"text-teal-600 dark:text-teal-400"},"Test-time scaling"),e(" â€” more inference compute improves accuracy on hard tasks.")]),t("li",null,[t("strong",{class:"font-semibold text-gray-700 dark:text-gray-200"},"Pros:"),e(" Excels at math, code, and multi-step tasks via tools (Python, browsing) and structured thought.")]),t("li",null,[t("strong",{class:"font-semibold text-gray-700 dark:text-gray-200"},"Cons:"),e(" Longer outputs, higher latency, and more complex failure modes.")])])])],-1)])]),_:1},16))}};export{w as default};
