import{o as s,b as u,w as i,g as l,ad as n,v as a,x as c,T as e}from"./modules/vue-CVEjzCsQ.js";import{I as p}from"./slidev/default-BqaX2aeV.js";import{u as d,f as g}from"./slidev/context-BxwITPeH.js";import"./index-CTBsFxrU.js";import"./modules/shiki-vBOq2oBG.js";const v={__name:"slides.md__slidev_10",setup(m){const{$clicksContext:o,$frontmatter:r}=d();return o.setup(),(f,t)=>(s(),u(p,a(c(e(g)(e(r),9))),{default:i(()=>[...t[0]||(t[0]=[l("h1",null,"Deployment: Memory, throughput, and efficiency",-1),l("div",{class:"grid grid-cols-2 gap-6 text-sm"},[l("div",null,[l("p",null,[l("strong",null,"Memory Footprint (A100/H100):")]),l("ul",null,[l("li",null,[n("120B: "),l("strong",null,"~80 GB"),n(" per device (with 4-bit KV cache)")]),l("li",null,[n("20B: "),l("strong",null,"~16 GB"),n(" per device ("),l("strong",null,"5× reduction"),n(")")])]),l("p",null,[l("strong",null,"Throughput & Latency:")]),l("ul",null,[l("li",null,[n("120B: "),l("strong",null,"128 tokens/s"),n("; 20B: "),l("strong",null,"178 tokens/s")]),l("li",null,"Multi-turn latency growth: 0.8→2.9s (120B, 10 turns)")])]),l("div",null,[l("p",null,[l("strong",null,"Efficiency:")]),l("ul",null,[l("li",null,[n("20B: "),l("strong",null,"2.6× less energy"),n(" per response at target accuracy")]),l("li",null,"MXFP4 on MoE weights")]),l("p",null,[l("strong",null,"Attention Architecture:")]),l("ul",null,[l("li",null,[n("Alternating "),l("strong",null,"banded"),n(" + "),l("strong",null,"dense"),n(", "),l("strong",null,"GQA"),n(", "),l("strong",null,"RoPE")])])])],-1),l("div",{class:"text-xs mt-4 opacity-70"}," Source: Model card Section 2.1, deployment analysis ",-1)])]),_:1},16))}};export{v as default};
