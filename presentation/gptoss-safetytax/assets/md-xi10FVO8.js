import{o as r,b as s,w as i,g as e,ad as t,v as u,x as c,T as o}from"./modules/vue-CVEjzCsQ.js";import{I as d}from"./slidev/default-BqaX2aeV.js";import{u as p,f as m}from"./slidev/context-BxwITPeH.js";import"./index-CTBsFxrU.js";import"./modules/shiki-vBOq2oBG.js";const x={__name:"slides.md__slidev_11",setup(g){const{$clicksContext:n,$frontmatter:a}=p();return n.setup(),(f,l)=>(r(),s(d,u(c(o(m)(o(a),10))),{default:i(()=>[...l[0]||(l[0]=[e("h1",null,"Safety testing and mitigation approach",-1),e("p",null,[e("strong",null,"Goal:"),t(" Test open-weight models reflecting how downstream actors can modify them")],-1),e("p",null,[e("strong",null,"Three key questions investigated:")],-1),e("ol",null,[e("li",null,[t("Does default gpt-oss-120b reach "),e("strong",null,'"High" capability'),t(" in Bio/Chem, Cyber, or AI Self-Improvement? → "),e("strong",null,"No")]),e("li",null,[t("Could adversarial actors "),e("strong",null,"fine-tune"),t(" it to High capability? → "),e("strong",null,"No"),t(" (even with robust internal FT + SAG review)")]),e("li",null,[t("Does releasing it "),e("strong",null,"advance the frontier"),t(" vs existing open models? → "),e("strong",null,"No"),t(" (other models already at or near this level)")])],-1),e("p",null,[e("strong",null,"Default safety approach:")],-1),e("ul",null,[e("li",null,[e("strong",null,"Deliberative alignment"),t(" to refuse disallowed content, resist jailbreaks, follow instruction hierarchy")]),e("li",null,"Evaluated on: disallowed content, jailbreaks, instruction hierarchy, hallucinations, bias")],-1),e("div",{class:"text-xs mt-4 opacity-70"}," Source: Model card Section 3 and Preparedness summary ",-1)])]),_:1},16))}};export{x as default};
