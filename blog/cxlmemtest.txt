1:"$Sreact.fragment"
2:I[1478,["874","static/chunks/874-8edb22cc7428423c.js","650","static/chunks/650-5bb235cd9bfca45d.js","177","static/chunks/app/layout-66df3ac28fcfbced.js"],"ThemeProviders"]
3:I[4091,["874","static/chunks/874-8edb22cc7428423c.js","650","static/chunks/650-5bb235cd9bfca45d.js","177","static/chunks/app/layout-66df3ac28fcfbced.js"],"default"]
4:I[9243,["874","static/chunks/874-8edb22cc7428423c.js","650","static/chunks/650-5bb235cd9bfca45d.js","177","static/chunks/app/layout-66df3ac28fcfbced.js"],""]
5:I[7392,["874","static/chunks/874-8edb22cc7428423c.js","650","static/chunks/650-5bb235cd9bfca45d.js","177","static/chunks/app/layout-66df3ac28fcfbced.js"],"KBarSearchProvider"]
6:I[6874,["874","static/chunks/874-8edb22cc7428423c.js","63","static/chunks/63-d245e42a784ca56d.js","909","static/chunks/app/blog/%5B...slug%5D/page-1ed2702378ba9d6b.js"],""]
e:I[8393,[],""]
:HL["/_next/static/media/36966cca54120369-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/4ac7c0f872b74ee7.css","style"]
:HL["/_next/static/css/a06d7e24bf9a7d93.css","style"]
:HL["/_next/static/css/7246298b30c42979.css","style"]
0:{"P":null,"b":"MYXrWUjg0HELsl6zLYF_6","p":"","c":["","blog","cxlmemtest"],"i":false,"f":[[["",{"children":["blog",{"children":[["slug","cxlmemtest","c"],{"children":["__PAGE__",{}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/4ac7c0f872b74ee7.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}],["$","link","1",{"rel":"stylesheet","href":"/_next/static/css/a06d7e24bf9a7d93.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en-us","className":"__variable_dd5b2f scroll-smooth","suppressHydrationWarning":true,"children":[["$","link",null,{"rel":"apple-touch-icon","sizes":"76x76","href":"/static/favicons/apple-touch-icon.png"}],["$","link",null,{"rel":"icon","type":"image/svg+xml","href":"/static/favicons/favicon.svg"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"32x32","href":"/static/favicons/favicon-32x32.png"}],["$","link",null,{"rel":"icon","type":"image/png","sizes":"16x16","href":"/static/favicons/favicon-16x16.png"}],["$","link",null,{"rel":"manifest","href":"/static/favicons/site.webmanifest"}],["$","link",null,{"rel":"mask-icon","href":"/static/favicons/safari-pinned-tab.svg","color":"#5bbad5"}],["$","meta",null,{"name":"msapplication-TileColor","content":"#000000"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: light)","content":"#fff"}],["$","meta",null,{"name":"theme-color","media":"(prefers-color-scheme: dark)","content":"#000"}],["$","link",null,{"rel":"alternate","type":"application/rss+xml","href":"/feed.xml"}],["$","body",null,{"className":"pl-[calc(100vw-100%)] text-black antialiased dark:text-white min-h-screen","children":["$","$L2",null,{"children":[["$","$L3",null,{}],["$undefined","$undefined","$undefined",["$","$L4",null,{"async":true,"defer":true,"src":"https://analytics.umami.is/script.js"}],"$undefined","$undefined"],["$","div",null,{"className":"min-h-screen flex flex-col justify-center py-8","children":["$","div",null,{"className":"content-glass mx-auto w-full max-w-5xl px-4 sm:px-6 xl:px-8 py-8","children":["$","$L5",null,{"kbarConfig":{"searchDocumentsPath":"/search.json"},"children":[["$","header",null,{"className":"flex items-center w-full justify-between py-6 border-b border-gray-200/30 dark:border-gray-700/30","children":[["$","$L6",null,{"className":"break-words","href":"/","aria-label":"yunwei37","children":["$","div",null,{"className":"flex items-center","children":[["$","div",null,{"className":"mr-3","children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","width":40,"height":40,"fill":"none","children":[["$","defs",null,{"children":[["$","linearGradient",null,{"id":"logo_svg__a","x1":"0%","x2":"100%","y1":"0%","y2":"100%","children":[["$","stop",null,{"offset":"0%","style":{"stopColor":"#3b82f6","stopOpacity":1}}],["$","stop",null,{"offset":"100%","style":{"stopColor":"#06b6d4","stopOpacity":1}}]]}],["$","linearGradient",null,{"id":"logo_svg__b","x1":"0%","x2":"100%","y1":"0%","y2":"100%","children":[["$","stop",null,{"offset":"0%","style":{"stopColor":"#8b5cf6","stopOpacity":1}}],["$","stop",null,{"offset":"100%","style":{"stopColor":"#3b82f6","stopOpacity":1}}]]}]]}],["$","circle",null,{"cx":20,"cy":20,"r":18,"fill":"url(#logo_svg__a)","opacity":0.1}],["$","path",null,{"fill":"url(#logo_svg__a)","d":"m12 8 6 10v10h4V18l6-10h-4l-4 6-4-6Z"}],["$","path",null,{"fill":"url(#logo_svg__b)","d":"m8 24 4 8 4-8 4 8 4-8h8v4h-6l-4 8-4-8-4 8-4-8H8Z","opacity":0.8}],["$","circle",null,{"cx":32,"cy":12,"r":2,"fill":"url(#logo_svg__b)"}],["$","circle",null,{"cx":8,"cy":12,"r":1.5,"fill":"url(#logo_svg__a)","opacity":0.6}]]}]}],["$","div",null,{"className":"hidden text-2xl font-bold sm:block hover:text-primary-600 dark:hover:text-primary-400 transition-colors","children":"yunwei37"}]]}]}],["$","div",null,{"className":"flex items-center space-x-4","children":[["$","div",null,{"className":"no-scrollbar hidden items-center space-x-2 sm:flex","children":[["$","$L6","Blog",{"className":"px-3 py-2 rounded-lg transition-all duration-200 font-medium hover:text-primary-600 dark:hover:text-primary-400","href":"/blog","children":"Blog"}],["$","$L6","Docs",{"className":"px-3 py-2 rounded-lg transition-all duration-200 font-medium hover:text-primary-600 dark:hover:text-primary-400","href":"/docs","children":"Docs"}],["$","$L6","Tags",{"className":"px-3 py-2 rounded-lg transition-all duration-200 font-medium hover:text-primary-600 dark:hover:text-primary-400","href":"/tags","children":"Tags"}],["$","$L6","About",{"className":"px-3 py-2 rounded-lg transition-all duration-200 font-medium hover:text-primary-600 dark:hover:text-primary-400","href":"/about","children":"About"}]]}],"$L7"]}]]}],"$L8","$L9"]}]}]}]]}]}]]}]]}],{"children":["blog","$La",{"children":[["slug","cxlmemtest","c"],"$Lb",{"children":["__PAGE__","$Lc",{},null,false]},null,false]},null,false]},null,false],"$Ld",false]],"m":"$undefined","G":["$e",[]],"s":false,"S":true}
f:I[4159,["874","static/chunks/874-8edb22cc7428423c.js","650","static/chunks/650-5bb235cd9bfca45d.js","177","static/chunks/app/layout-66df3ac28fcfbced.js"],"KBarButton"]
10:I[1762,["874","static/chunks/874-8edb22cc7428423c.js","650","static/chunks/650-5bb235cd9bfca45d.js","177","static/chunks/app/layout-66df3ac28fcfbced.js"],"default"]
11:I[7298,["874","static/chunks/874-8edb22cc7428423c.js","650","static/chunks/650-5bb235cd9bfca45d.js","177","static/chunks/app/layout-66df3ac28fcfbced.js"],"default"]
12:I[7555,[],""]
13:I[1295,[],""]
1e:I[9665,[],"OutletBoundary"]
20:I[4911,[],"AsyncMetadataOutlet"]
22:I[9665,[],"ViewportBoundary"]
24:I[9665,[],"MetadataBoundary"]
25:"$Sreact.suspense"
7:["$","div",null,{"className":"flex items-center space-x-2","children":[["$","$Lf",null,{"aria-label":"Search","className":"p-2 rounded-lg transition-all duration-200","children":["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","fill":"none","viewBox":"0 0 24 24","strokeWidth":1.5,"stroke":"currentColor","className":"h-6 w-6 hover:text-primary-600 dark:hover:text-primary-400 transition-colors","children":["$","path",null,{"strokeLinecap":"round","strokeLinejoin":"round","d":"M21 21l-5.197-5.197m0 0A7.5 7.5 0 105.196 5.196a7.5 7.5 0 0010.607 10.607z"}]}]}],["$","$L10",null,{}],["$","$L11",null,{}]]}]
8:["$","main",null,{"className":"py-6","children":["$","$L12",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L13",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","div",null,{"className":"flex flex-col items-start justify-start md:mt-24 md:flex-row md:items-center md:justify-center md:space-x-6","children":[["$","div",null,{"className":"space-x-2 pt-6 pb-8 md:space-y-5","children":["$","h1",null,{"className":"text-6xl leading-9 font-extrabold tracking-tight md:border-r-2 md:px-6 md:text-8xl md:leading-14","children":"404"}]}],["$","div",null,{"className":"max-w-md","children":[["$","p",null,{"className":"mb-4 text-xl leading-normal font-bold md:text-2xl","children":"Sorry we couldn't find this page."}],["$","p",null,{"className":"mb-8","children":"But dont worry, you can find plenty of other things on our homepage."}],["$","$L6",null,{"className":"focus:shadow-outline-blue inline rounded-lg border border-transparent bg-blue-600 px-4 py-2 text-sm leading-5 font-medium text-white shadow-xs transition-colors duration-150 hover:bg-blue-700 focus:outline-hidden dark:hover:bg-blue-500","href":"/","children":"Back to homepage"}]]}]]}],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]
9:["$","footer",null,{"className":"border-t border-gray-200/30 dark:border-gray-700/30 pt-8","children":["$","div",null,{"className":"flex flex-col items-center space-y-6","children":[["$","div",null,{"className":"flex flex-wrap justify-center gap-4","children":[["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"mailto:yunwei356@gmail.com","children":[["$","span",null,{"className":"sr-only","children":"mail"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 20 20","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Mail"}],["$","path",null,{"d":"M2.003 5.884L10 9.882l7.997-3.998A2 2 0 0016 4H4a2 2 0 00-1.997 1.884z"}],["$","path",null,{"d":"M18 8.118l-8 4-8-4V14a2 2 0 002 2h12a2 2 0 002-2V8.118z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://github.com/yunwei37","children":[["$","span",null,{"className":"sr-only","children":"github"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"GitHub"}],["$","path",null,{"d":"M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://facebook.com","children":[["$","span",null,{"className":"sr-only","children":"facebook"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Facebook"}],["$","path",null,{"d":"M24 12.073c0-6.627-5.373-12-12-12s-12 5.373-12 12c0 5.99 4.388 10.954 10.125 11.854v-8.385H7.078v-3.47h3.047V9.43c0-3.007 1.792-4.669 4.533-4.669 1.312 0 2.686.235 2.686.235v2.953H15.83c-1.491 0-1.956.925-1.956 1.874v2.25h3.328l-.532 3.47h-2.796v8.385C19.612 23.027 24 18.062 24 12.073z"}]]}]]}],["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://youtube.com","children":[["$","span",null,{"className":"sr-only","children":"youtube"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Youtube"}],["$","path",null,{"d":"M23.499 6.203a3.008 3.008 0 00-2.089-2.089c-1.87-.501-9.4-.501-9.4-.501s-7.509-.01-9.399.501a3.008 3.008 0 00-2.088 2.09A31.258 31.26 0 000 12.01a31.258 31.26 0 00.523 5.785 3.008 3.008 0 002.088 2.089c1.869.502 9.4.502 9.4.502s7.508 0 9.399-.502a3.008 3.008 0 002.089-2.09 31.258 31.26 0 00.5-5.784 31.258 31.26 0 00-.5-5.808zm-13.891 9.4V8.407l6.266 3.604z"}]]}]]}],"$L14","$L15","$L16","$L17","$L18","$L19","$L1a"]}],"$L1b","$L1c"]}]}]
a:["$","$1","c",{"children":[null,["$","$L12",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L13",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
b:["$","$1","c",{"children":[null,["$","$L12",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L13",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}]
c:["$","$1","c",{"children":["$L1d",[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/7246298b30c42979.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","$L1e",null,{"children":["$L1f",["$","$L20",null,{"promise":"$@21"}]]}]]}]
d:["$","$1","h",{"children":[null,[["$","$L22",null,{"children":"$L23"}],["$","meta",null,{"name":"next-size-adjust","content":""}]],["$","$L24",null,{"children":["$","div",null,{"hidden":true,"children":["$","$25",null,{"fallback":null,"children":"$L26"}]}]}]]}]
14:["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.linkedin.com/in/yusheng-zheng-611920280","children":[["$","span",null,{"className":"sr-only","children":"linkedin"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Linkedin"}],["$","path",null,{"d":"M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"}]]}]]}]
15:null
16:["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://bsky.app/","children":[["$","span",null,{"className":"sr-only","children":"bluesky"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Bluesky"}],["$","path",null,{"d":"M12 10.8c-1.087-2.114-4.046-6.053-6.798-7.995C2.566.944 1.561 1.266.902 1.565C.139 1.908 0 3.08 0 3.768c0 .69.378 5.65.624 6.479c.815 2.736 3.713 3.66 6.383 3.364q.204-.03.415-.056q-.207.033-.415.056c-3.912.58-7.387 2.005-2.83 7.078c5.013 5.19 6.87-1.113 7.823-4.308c.953 3.195 2.05 9.271 7.733 4.308c4.267-4.308 1.172-6.498-2.74-7.078a9 9 0 0 1-.415-.056q.21.026.415.056c2.67.297 5.568-.628 6.383-3.364c.246-.828.624-5.79.624-6.478c0-.69-.139-1.861-.902-2.206c-.659-.298-1.664-.62-4.3 1.24C16.046 4.748 13.087 8.687 12 10.8"}]]}]]}]
17:["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://x.com/yunwei37","children":[["$","span",null,{"className":"sr-only","children":"x"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"X"}],["$","path",null,{"d":"M18.901 1.153h3.68l-8.04 9.19L24 22.846h-7.406l-5.8-7.584-6.638 7.584H.474l8.6-9.83L0 1.154h7.594l5.243 6.932ZM17.61 20.644h2.039L6.486 3.24H4.298Z"}]]}]]}]
27:T69f,M12 0C8.74 0 8.333.015 7.053.072 5.775.132 4.905.333 4.14.63c-.789.306-1.459.717-2.126 1.384S.935 3.35.63 4.14C.333 4.905.131 5.775.072 7.053.012 8.333 0 8.74 0 12s.015 3.667.072 4.947c.06 1.277.261 2.148.558 2.913.306.788.717 1.459 1.384 2.126.667.666 1.336 1.079 2.126 1.384.766.296 1.636.499 2.913.558C8.333 23.988 8.74 24 12 24s3.667-.015 4.947-.072c1.277-.06 2.148-.262 2.913-.558.788-.306 1.459-.718 2.126-1.384.666-.667 1.079-1.335 1.384-2.126.296-.765.499-1.636.558-2.913.06-1.28.072-1.687.072-4.947s-.015-3.667-.072-4.947c-.06-1.277-.262-2.149-.558-2.913-.306-.789-.718-1.459-1.384-2.126C21.319 1.347 20.651.935 19.86.63c-.765-.297-1.636-.499-2.913-.558C15.667.012 15.26 0 12 0zm0 2.16c3.203 0 3.585.016 4.85.071 1.17.055 1.805.249 2.227.415.562.217.96.477 1.382.896.419.42.679.819.896 1.381.164.422.36 1.057.413 2.227.057 1.266.07 1.646.07 4.85s-.015 3.585-.074 4.85c-.061 1.17-.256 1.805-.421 2.227-.224.562-.479.96-.899 1.382-.419.419-.824.679-1.38.896-.42.164-1.065.36-2.235.413-1.274.057-1.649.07-4.859.07-3.211 0-3.586-.015-4.859-.074-1.171-.061-1.816-.256-2.236-.421-.569-.224-.96-.479-1.379-.899-.421-.419-.69-.824-.9-1.38-.165-.42-.359-1.065-.42-2.235-.045-1.26-.061-1.649-.061-4.844 0-3.196.016-3.586.061-4.861.061-1.17.255-1.814.42-2.234.21-.57.479-.96.9-1.381.419-.419.81-.689 1.379-.898.42-.166 1.051-.361 2.221-.421 1.275-.045 1.65-.06 4.859-.06l.045.03zm0 3.678c-3.405 0-6.162 2.76-6.162 6.162 0 3.405 2.76 6.162 6.162 6.162 3.405 0 6.162-2.76 6.162-6.162 0-3.405-2.76-6.162-6.162-6.162zM12 16c-2.21 0-4-1.79-4-4s1.79-4 4-4 4 1.79 4 4-1.79 4-4 4zm7.846-10.405c0 .795-.646 1.44-1.44 1.44-.795 0-1.44-.646-1.44-1.44 0-.794.646-1.439 1.44-1.439.793-.001 1.44.645 1.44 1.439z18:["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.instagram.com","children":[["$","span",null,{"className":"sr-only","children":"instagram"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Instagram"}],["$","path",null,{"d":"$27"}]]}]]}]
28:T498,M12.186 24h-.007c-3.581-.024-6.334-1.205-8.184-3.509C2.35 18.44 1.5 15.586 1.472 12.01v-.017c.03-3.579.879-6.43 2.525-8.482C5.845 1.205 8.6.024 12.18 0h.014c2.746.02 5.043.725 6.826 2.098 1.677 1.29 2.858 3.13 3.509 5.467l-2.04.569c-1.104-3.96-3.898-5.984-8.304-6.015-2.91.022-5.11.936-6.54 2.717C4.307 6.504 3.616 8.914 3.589 12c.027 3.086.718 5.496 2.057 7.164 1.43 1.783 3.631 2.698 6.54 2.717 2.623-.02 4.358-.631 5.8-2.045 1.647-1.613 1.618-3.593 1.09-4.798-.31-.71-.873-1.3-1.634-1.75-.192 1.352-.622 2.446-1.284 3.272-.886 1.102-2.14 1.704-3.73 1.79-1.202.065-2.361-.218-3.259-.801-1.063-.689-1.685-1.74-1.752-2.964-.065-1.19.408-2.285 1.33-3.082.88-.76 2.119-1.207 3.583-1.291a13.853 13.853 0 0 1 3.02.142c-.126-.742-.375-1.332-.75-1.757-.513-.586-1.308-.883-2.359-.89h-.029c-.844 0-1.992.232-2.721 1.32L7.734 7.847c.98-1.454 2.568-2.256 4.478-2.256h.044c3.194.02 5.097 1.975 5.287 5.388.108.046.216.094.321.142 1.49.7 2.58 1.761 3.154 3.07.797 1.82.871 4.79-1.548 7.158-1.85 1.81-4.094 2.628-7.277 2.65Zm1.003-11.69c-.242 0-.487.007-.739.021-1.836.103-2.98.946-2.916 2.143.067 1.256 1.452 1.839 2.784 1.767 1.224-.065 2.818-.543 3.086-3.71a10.5 10.5 0 0 0-2.215-.221z19:["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://www.threads.net","children":[["$","span",null,{"className":"sr-only","children":"threads"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Threads"}],["$","path",null,{"d":"$28"}]]}]]}]
1a:["$","a",null,{"className":"text-sm text-gray-500 transition hover:text-gray-600","target":"_blank","rel":"noopener noreferrer","href":"https://medium.com","children":[["$","span",null,{"className":"sr-only","children":"medium"}],["$","svg",null,{"xmlns":"http://www.w3.org/2000/svg","viewBox":"0 0 24 24","className":"hover:text-primary-500 dark:hover:text-primary-400 fill-current text-gray-700 dark:text-gray-200 h-6 w-6","children":[["$","title",null,{"children":"Medium"}],["$","path",null,{"d":"M13.54 12a6.8 6.8 0 01-6.77 6.82A6.8 6.8 0 010 12a6.8 6.8 0 016.77-6.82A6.8 6.8 0 0113.54 12zM20.96 12c0 3.54-1.51 6.42-3.38 6.42-1.87 0-3.39-2.88-3.39-6.42s1.52-6.42 3.39-6.42 3.38 2.88 3.38 6.42M24 12c0 3.17-.53 5.75-1.19 5.75-.66 0-1.19-2.58-1.19-5.75s.53-5.75 1.19-5.75C23.47 6.25 24 8.83 24 12z"}]]}]]}]
1b:["$","div",null,{"className":"flex space-x-2 text-sm opacity-80","children":[["$","div",null,{"children":"Yusheng Zheng"}],["$","div",null,{"children":" • "}],["$","div",null,{"children":"© 2026"}],["$","div",null,{"children":" • "}],["$","$L6",null,{"className":"hover:text-primary-500 transition-colors","href":"/","children":"云微的胡思乱想"}]]}]
1c:["$","div",null,{"className":"text-sm opacity-60","children":["$","a",null,{"className":"hover:text-primary-500 transition-colors","target":"_blank","rel":"noopener noreferrer","href":"https://github.com/timlrx/tailwind-nextjs-starter-blog","children":"Tailwind Nextjs Theme"}]}]
29:I[1839,["874","static/chunks/874-8edb22cc7428423c.js","63","static/chunks/63-d245e42a784ca56d.js","909","static/chunks/app/blog/%5B...slug%5D/page-1ed2702378ba9d6b.js"],"default"]
2a:I[3063,["874","static/chunks/874-8edb22cc7428423c.js","63","static/chunks/63-d245e42a784ca56d.js","909","static/chunks/app/blog/%5B...slug%5D/page-1ed2702378ba9d6b.js"],"Image"]
1d:[["$","script",null,{"type":"application/ld+json","dangerouslySetInnerHTML":{"__html":"{\"@context\":\"https://schema.org\",\"@type\":\"BlogPosting\",\"headline\":\"**The Modern Memory Testing Arsenal -- A Complete Guide to Benchmarking Tools for Next-Gen Memory Systems**\",\"datePublished\":\"2025-06-21T16:00:00.000Z\",\"dateModified\":\"2025-06-21T16:00:00.000Z\",\"image\":\"/static/images/twitter-card.png\",\"url\":\"https://www.yunwei37.com/blog/cxlmemtest\",\"author\":[{\"@type\":\"Person\",\"name\":\"Yusheng Zheng (云微)\"}]}"}}],["$","section",null,{"className":"mx-auto max-w-3xl px-4 sm:px-6 xl:max-w-5xl xl:px-0","children":[["$","$L29",null,{}],["$","article",null,{"className":"content-glass p-8","children":["$","div",null,{"className":"xl:divide-y xl:divide-gray-200/30 xl:dark:divide-gray-700/30","children":[["$","header",null,{"className":"pt-6 xl:pb-6","children":["$","div",null,{"className":"space-y-4 text-center","children":[["$","dl",null,{"className":"space-y-4","children":["$","div",null,{"children":[["$","dt",null,{"className":"sr-only","children":"Published on"}],["$","dd",null,{"className":"text-base leading-6 font-medium text-gray-600 dark:text-gray-300","children":["$","time",null,{"dateTime":"2025-06-21T16:00:00.000Z","children":"Saturday, June 21, 2025"}]}]]}]}],["$","div",null,{"children":["$","h1",null,{"className":"text-3xl leading-9 font-extrabold tracking-tight sm:text-4xl sm:leading-10 md:text-5xl md:leading-14","children":"**The Modern Memory Testing Arsenal -- A Complete Guide to Benchmarking Tools for Next-Gen Memory Systems**"}]}]]}]}],["$","div",null,{"className":"grid-rows-[auto_1fr] divide-y divide-gray-200/30 pb-8 xl:grid xl:grid-cols-4 xl:gap-x-8 xl:divide-y-0 dark:divide-gray-700/30","children":[["$","dl",null,{"className":"pt-6 pb-10 xl:border-b xl:border-gray-200/30 xl:pt-11 xl:dark:border-gray-700/30","children":[["$","dt",null,{"className":"sr-only","children":"Authors"}],["$","dd",null,{"children":["$","ul",null,{"className":"flex flex-wrap justify-center gap-4 sm:space-x-12 xl:block xl:space-y-6 xl:space-x-0","children":[["$","li","Yusheng Zheng (云微)",{"className":"flex items-center space-x-3 glass p-4 rounded-xl","children":[["$","$L2a",null,{"src":"/static/images/avatar.png","width":38,"height":38,"alt":"avatar","className":"h-10 w-10 rounded-full"}],["$","dl",null,{"className":"text-sm leading-5 font-medium whitespace-nowrap","children":[["$","dt",null,{"className":"sr-only","children":"Name"}],["$","dd",null,{"className":"text-gray-900 dark:text-gray-100","children":"Yusheng Zheng (云微)"}],["$","dt",null,{"className":"sr-only","children":"Twitter"}],["$","dd",null,{"children":["$","a",null,{"className":"text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 transition-colors","target":"_blank","rel":"noopener noreferrer","href":"https://twitter.com/yunwei37","children":"@yunwei37"}]}]]}]]}]]}]}]]}],["$","div",null,{"className":"divide-y divide-gray-200/30 xl:col-span-3 xl:row-span-2 xl:pb-0 dark:divide-gray-700/30","children":[["$","div",null,{"className":"prose dark:prose-invert max-w-none pt-10 pb-8 text-gray-700 dark:text-gray-200","children":[["$","h1",null,{"className":"content-header","id":"the-modern-memory-testing-arsenal----a-complete-guide-to-benchmarking-tools-for-next-gen-memory-systems","children":[["$","a",null,{"className":"break-words","href":"#the-modern-memory-testing-arsenal----a-complete-guide-to-benchmarking-tools-for-next-gen-memory-systems","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],"$L2b"]}],"$L2c","$L2d","$L2e","$L2f","$L30","$L31","$L32","$L33","$L34","$L35","$L36","$L37","$L38","$L39","$L3a","$L3b","$L3c","$L3d","$L3e","$L3f","$L40","$L41","$L42","$L43","$L44","$L45","$L46","$L47","$L48","$L49","$L4a","$L4b","$L4c","$L4d","$L4e","$L4f"]}],"$L50","$L51"]}],"$L52"]}]]}]}]]}]]
7e:I[1449,["874","static/chunks/874-8edb22cc7428423c.js","63","static/chunks/63-d245e42a784ca56d.js","909","static/chunks/app/blog/%5B...slug%5D/page-1ed2702378ba9d6b.js"],"default"]
2b:["$","strong",null,{"children":"The Modern Memory Testing Arsenal -- A Complete Guide to Benchmarking Tools for Next-Gen Memory Systems"}]
2c:["$","h2",null,{"className":"content-header","id":"introduction","children":[["$","a",null,{"className":"break-words","href":"#introduction","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],["$","strong",null,{"children":"Introduction"}]]}]
2d:["$","p",null,{"children":"Memory systems are evolving rapidly. From traditional DDR DRAM to high-bandwidth memory (HBM), persistent memory (PMEM), and the emerging Compute Express Link (CXL) technology, today's systems feature complex heterogeneous memory hierarchies that demand sophisticated evaluation approaches."}]
2e:["$","p",null,{"children":"This comprehensive guide surveys the cutting-edge tools and methodologies available for testing, benchmarking, and profiling modern memory systems. Whether you're a hardware architect designing next-generation memory controllers, a software developer optimizing applications for heterogeneous memory, or a researcher exploring memory system co-design, this survey provides a roadmap to the essential tools shaping memory system evaluation from 2018 to 2025."}]
2f:["$","p",null,{"children":"We cover everything from synthetic workload generators that can clone application memory behavior, to trace replay frameworks that enable reproducible testing, specialized benchmark suites for emerging technologies, and profiling tools that provide deep insights into memory performance bottlenecks. The landscape has evolved from simple bandwidth and latency measurements to sophisticated AI-driven workload synthesis and unified frameworks that span multiple memory technologies."}]
30:["$","h2",null,{"className":"content-header","id":"1-synthetic-memory-workload-generators-and-proxy-benchmarks","children":[["$","a",null,{"className":"break-words","href":"#1-synthetic-memory-workload-generators-and-proxy-benchmarks","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],["$","strong",null,{"children":"1. Synthetic Memory Workload Generators and Proxy Benchmarks"}]]}]
31:["$","p",null,{"children":["Synthetic workload generators create artificial memory access patterns that statistically mimic real applications. They enable faster simulation and protect proprietary code by ",["$","strong",null,{"children":"cloning"}]," memory behavior. Key projects in this area include classic ",["$","strong",null,{"children":"reuse-distance"}]," based models and recent ML-driven approaches:"]}]
32:["$","ul",null,{"children":[["$","li",null,{"children":[["$","strong",null,{"children":"WEST (HPCA 2012)"}]," – ",["$","em",null,{"children":"Workload Emulation using Stochastic Traces"}]," is a seminal black-box cloning technique to replicate a program’s ",["$","strong",null,{"children":"data cache access behavior"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.researchgate.net/publication/241627523_WEST_Cloning_data_cache_behavior_using_Stochastic_Traces#:~:text=replicating%20data%20cache%20behavior,We%20evaluated","children":"researchgate.net"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.researchgate.net/publication/241627523_WEST_Cloning_data_cache_behavior_using_Stochastic_Traces#:~:text=IPC%20model%20to%20control%20the,for%20over%20600%20configurations","children":"researchgate.net"}],". WEST profiles reuse-distance patterns and generates a synthetic trace (“clone”) that yields nearly identical cache miss statistics as the original workload. It achieved ",["$","code",null,{"children":"<0.5"}],"% error in cache miss ratio across 1000+ cache configurations",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.researchgate.net/publication/241627523_WEST_Cloning_data_cache_behavior_using_Stochastic_Traces#:~:text=sizes%2C%20associativities%2C%20write%20policies%2C%20replacement,for%20over%20600%20configurations","children":"researchgate.net"}],". ",["$","em",null,{"children":"Limitation:"}]," WEST targeted caches only (temporal locality), requiring separate models per cache configuration."]}],["$","li",null,{"children":[["$","strong",null,{"children":"STM (HPCA 2014)"}]," – ",["$","em",null,{"children":"Spatial and Temporal Memory cloning"}]," extended WEST by modeling ",["$","strong",null,{"children":"both"}]," spatial locality (access strides) and temporal locality. By incorporating memory-access ",["$","strong",null,{"children":"strides"}]," along with reuse distances, STM’s clones capture a program’s cache and memory behavior more comprehensively. ",["$","em",null,{"children":"Platform:"}]," x86 simulation; ",["$","em",null,{"children":"Limitation:"}]," needed microarchitecture-specific metrics and produced large trace metadata."]}],["$","li",null,{"children":[["$","strong",null,{"children":"MEMST (MEMSYS 2015)"}]," – ",["$","em",null,{"children":"Memory EMulation using Stochastic Traces"}]," applied workload cloning to ",["$","strong",null,{"children":"DRAM and memory controller"}]," behavior",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://dl.acm.org/doi/10.1145/2818950.2818971#:~:text=We%20propose%20Memory%20EMulation%20using,capturing%20DRAM%20and%20MC%20behavior","children":"dl.acm.org"}],". It profiles memory-level interleaving and timing, then generates synthetic memory traffic that closely emulates an application’s DRAM access patterns. MEMST provided a “black-box” clone of memory subsystem usage, addressing cases where sharing full memory traces is impractical due to size or confidentiality",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://dl.acm.org/doi/10.1145/2818950.2818971#:~:text=We%20propose%20Memory%20EMulation%20using,capturing%20DRAM%20and%20MC%20behavior","children":"dl.acm.org"}],"."]}],["$","li",null,{"children":[["$","strong",null,{"children":"HRD (ISPASS 2017)"}]," – ",["$","em",null,{"children":"Hierarchical Reuse Distance"}]," profiling introduced multi-granularity reuse distance histograms (e.g. 64B, 4KB) to better capture cache and TLB locality. HRD improved accuracy for multi-level cache hierarchy modeling, influencing later tools like HALO."]}],"$L53","$L54","$L55","$L56","$L57","$L58"]}]
33:["$","p",null,{"children":[["$","strong",null,{"children":"Trend:"}]," Over the past five years, synthetic workload generation has grown more sophisticated – from basic cache-centric models to full-system proxies and ML-driven trace synthesis. The design trade-off is between ",["$","strong",null,{"children":"fidelity"}]," (capturing complex spatial/temporal patterns, cross-component interactions) and ",["$","strong",null,{"children":"practicality"}]," (trace size, automation, confidentiality). There is a clear trend toward ",["$","em",null,{"children":"automating"}]," clone creation (black-box profiling) and using ",["$","em",null,{"children":"statistical or ML models"}]," to shrink huge real traces into lightweight proxies. However, gaps remain in cloning ",["$","strong",null,{"children":"multi-threaded"}]," sharing patterns, coherent shared-memory behavior, and emerging access patterns like those in persistent memory or GPUs. These are active research directions, with opportunities to combine ML with domain-specific knowledge for even more accurate workload generators."]}]
34:["$","h2",null,{"className":"content-header","id":"2-trace-based-memory-replay-frameworks","children":[["$","a",null,{"className":"break-words","href":"#2-trace-based-memory-replay-frameworks","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],["$","strong",null,{"children":"2. Trace-Based Memory Replay Frameworks"}]]}]
35:["$","p",null,{"children":["Trace replay tools take recorded memory address traces or access logs and ",["$","strong",null,{"children":"replay"}]," them to evaluate memory systems. They allow reproducible testing of memory behavior using real workloads’ patterns. Modern frameworks often handle trace ",["$","em",null,{"children":"collection"}],", ",["$","em",null,{"children":"compression"}],", and ",["$","em",null,{"children":"playback"}],":"]}]
36:["$","ul",null,{"children":[["$","li",null,{"children":[["$","strong",null,{"children":"Intel PinPlay / TraceMonkey (2010s)"}]," – Although a bit older, Intel’s PinPlay toolkit (built on Pin) pioneered deterministic recording of program execution and memory traces, then replaying them for architecture simulation. It enabled ",["$","em",null,{"children":"phase slicing"}]," and repetition of long memory traces with consistency. Many later tools built on Pin for trace collection (e.g., ScalaMemTrace, below)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"ScalaMemTrace (2011)"}]," – A framework for ",["$","strong",null,{"children":"lossless compression"}]," and replay of memory traces in HPC SPMD programs. It introduced an “Extended PRSD” compression that kept trace sizes near-constant even as execution scaled. For instance, memory traces of large matrix operations were compressed by orders of magnitude and could be replayed with over 90% accuracy for complex apps (some error due to minor numeric differences). ScalaMemTrace integrated with Pin and MPI, demonstrating parallel trace capture and deterministic replay for multi-node runs. ",["$","em",null,{"children":"Limitation:"}]," Instrumentation overhead can be high (Pin slowdown and large trace post-processing time)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"SynchroTrace (Tufts, 2013)"}]," – A two-step ",["$","strong",null,{"children":"trace-driven simulation"}]," methodology. It splits program execution into ",["$","em",null,{"children":"synchronization intervals"}],", records memory accesses per interval, then replays them in a simulator to model multicore memory systems. By preserving happens-before relationships in traces, SynchroTrace enabled faster exploration of multicore cache designs."]}],["$","li",null,{"children":[["$","strong",null,{"children":"TraceR (CODES 2016)"}]," – A ",["$","strong",null,{"children":"parallel trace replay"}]," tool for HPC interconnect and memory workloads. Built on the ROSS discrete-event simulator, TraceR can ingest MPI communication and memory traces and simulate a large-scale cluster’s network and memory hierarchy. It was used to predict congestion and memory access patterns in exascale network studies. ",["$","em",null,{"children":"Scope:"}]," Primarily HPC network+memory traces; ",["$","em",null,{"children":"Limitation:"}]," Requires traces collected from instrumented HPC runs (e.g., with Darshan, Extrae)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Gem5 “Trace CPU” Mode (2019)"}]," – The gem5 simulator introduced a Trace CPU model aimed at ",["$","strong",null,{"children":"fast memory system simulation"}]," by feeding pre-collected memory traces into the cache and memory models. This bypasses detailed core execution to focus on memory hierarchy performance. It’s useful for quickly evaluating new memory devices (e.g., a new DRAM or NVM timing model) using real trace workloads. ",["$","em",null,{"children":"Limitation:"}]," Lacks feedback from misses to CPU (timing is fixed by trace), so it cannot model adaptive software behavior."]}],["$","li",null,{"children":[["$","strong",null,{"children":"GLTraceSim (Uppsala, 2021)"}]," – A trace generation and replay framework specialized for ",["$","strong",null,{"children":"CPU–GPU heterogeneous memory systems"}],". GLTraceSim records detailed GPU memory access traces from graphics workloads and can replay them through either a high-level performance model or a cycle-level simulator. This allows researchers to study the effects of ",["$","strong",null,{"children":"unified memory, cache coherence, and memory scheduling"}]," in systems with CPUs and discrete GPUs. ","$L59"," workflow: it captures GPU memory accesses (e.g., from OpenGL or CUDA applications) and replays them to evaluate bandwidth usage, cache misses, and scheduling policies in a combined CPU+GPU memory hierarchy. ","$L5a"," x86 with NVIDIA GPUs (tracing via instrumented drivers). ","$L5b"," test HBM vs. GDDR effects, PCIe/CPU-GPU memory traffic."]}],"$L5c"]}]
37:["$","p",null,{"children":[["$","strong",null,{"children":"Trends:"}]," Modern trace replay frameworks emphasize ",["$","em",null,{"children":"scalability"}]," (handling multi-terabyte traces or thousands of nodes) and ",["$","em",null,{"children":"fidelity"}]," (preserving dependencies and timing). A recurring challenge is ",["$","strong",null,{"children":"trace size and privacy"}],". Compression techniques (run-length encoding, statistical compression) and synthetic trace generation (as in Section 1) are used to mitigate this. Moreover, concerns that sharing raw memory traces can leak proprietary information have spurred interest in trace ",["$","strong",null,{"children":"obfuscation"}]," or abstracted replay. The gap here is a lack of ",["$","strong",null,{"children":"standard trace formats"}]," and tooling for emerging domains like GPU memory and CXL memory networks. We see initial tools (GLTraceSim, TraceR) but more work is needed to integrate trace replay for new memory technologies (e.g. replaying Optane access patterns or CXL fabric traffic) – an open opportunity for tool developers."]}]
38:["$","h2",null,{"className":"content-header","id":"3-memory-benchmark-suites-and-mini-applications","children":[["$","a",null,{"className":"break-words","href":"#3-memory-benchmark-suites-and-mini-applications","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],["$","strong",null,{"children":"3. Memory Benchmark Suites and Mini-Applications"}]]}]
39:["$","p",null,{"children":"Benchmark suites provide ready-made programs or kernels to stress memory systems in specific ways. They range from microbenchmarks (probing one aspect of memory) to mini-applications (simplified real programs). Over the last few years, new suites have emerged to cover modern memory hierarchies (HBM, NVM), building on classic tests:"}]
3a:["$","ul",null,{"children":[["$","li",null,{"children":[["$","strong",null,{"children":"HPC Challenge (HPCC)"}]," – A longstanding suite (updated through 2018) measuring a range of memory access patterns. Notably, it includes ",["$","strong",null,{"children":"STREAM"}]," (sequential bandwidth test) and ",["$","strong",null,{"children":"RandomAccess"}]," (GUPS – random memory updates per second) to represent the extremes of streaming vs. pointer-chasing memory behavior",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://hpcchallenge.org/hpcc/#:~:text=3.%20STREAM%20,GUPS","children":"hpcchallenge.org"}],". HPCC results highlight memory performance on supercomputers, e.g., STREAM for bandwidth and GUPS for latency-bound throughput. These benchmarks remain foundational and are often the first check for memory on new CPUs/GPUs. ",["$","em",null,{"children":"Limitation:"}]," They are simple kernels, so real applications may exhibit more complex patterns (e.g., mixed access patterns or irregular strides)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"SPEC and GAP Benchmark suites"}]," – Standard CPU suites (SPEC CPU2017, GAP big-data benchmarks) include some memory-stress workloads (e.g., mcf for pointer-chasing, Graph500 for graph memory). For instance, Graph500’s BFS is ",["$","strong",null,{"children":"latency-bound"}]," and is used in hybrid memory research as a worst-case for high-latency memory. However, these suites are general-purpose; memory-focused analysis often uses specialized microbenchmarks instead."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Pointer-Chasing Microbenchmarks (P-Chase)"}]," – A classic microbenchmark to measure memory ",["$","em",null,{"children":"latency"}],". Variants of P-Chase create a long linked list and traverse it, defeating hardware prefetchers. For example, the LENS suite’s pointer-chase test generates random-access patterns in a large array to evaluate latency on different levels (L3 vs DRAM). Modern research still uses such microbenchmarks, sometimes in ",["$","strong",null,{"children":"auto-generated"}]," forms (e.g., to test new GPU memory, Mei and Chu 2020 proposed fine-grained GPU pointer chases). ",["$","em",null,{"children":"Use:"}]," Calibrating cache and DRAM latency, NUMA differences, or memory controller reordering."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Bandwidth and Stride Kernels:"}]," ",["$","strong",null,{"children":"STREAM"}]," (mentioned above) remains the de facto DRAM bandwidth test",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://hpcchallenge.org/hpcc/#:~:text=3.%20STREAM%20,GUPS","children":"hpcchallenge.org"}],". Others like ",["$","strong",null,{"children":"Spatter (SC 2019)"}]," focus on ",["$","strong",null,{"children":"irregular access patterns"}],": Spatter generates configurable gather/scatter memory access sequences and measures performance on CPUs and GPUs. It helps evaluate hardware support for scatter-gather (e.g., demonstrating how well a GPU’s memory coalescer handles strided or indexed loads). Tools like Spatter provide parameterized patterns (access density, strides) to stress caches and TLBs beyond simple streaming."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Data Structure Benchmarks:"}]," To mimic real workloads, suites of ",["$","em",null,{"children":"mini-apps"}]," cover common memory-intensive operations. For example, ",["$","strong",null,{"children":"XSBench (ANL 2014)"}]," is a mini-app for Monte Carlo particle transport that is essentially a ",["$","em",null,{"children":"random memory lookup"}]," benchmark (its performance is limited by memory latency, not compute). Such mini-apps (XSBench, LULESH for hydrodynamics, CloverLeaf for stencil updates, etc.) are heavily used in HPC to test new memory technologies – e.g., a Micron report on CXL memory used ","$L5d"," to examine memory bandwidth bottlenecks. These mini-apps are small (~1000 lines) but represent kernels of real scientific codes, giving more realistic memory access patterns (with loops, some temporal locality) than pure microbenchmarks."]}],"$L5e","$L5f"]}]
3b:["$","p",null,{"children":[["$","strong",null,{"children":"Trend:"}]," There’s a pattern of pairing ",["$","strong",null,{"children":"classic microbenchmarks"}]," (for fundamental limits like latency/bandwidth) with ",["$","strong",null,{"children":"proxy applications"}]," (for more complex memory usage) to evaluate memory systems. The past five years brought ",["$","em",null,{"children":"specialized suites"}]," for emerging tech: persistent memory (PerMA-Bench, WHISPER for PMem reliability testing), disaggregated memory (some CloudSuite benchmarks for far memory), and GPU memory (Rodinia, AI benchmarks) to ensure coverage of HBM usage. One noticeable gap is the lack of a ",["$","em",null,{"children":"standardized heterogeneous memory benchmark suite"}]," – e.g., something that in one package tests a system’s DRAM, HBM, NVM, and CXL performance in various combinations. The MESS framework (next section) attempts to fill part of this gap with a holistic approach, but an easy-to-run suite for practitioners is an open opportunity. Additionally, current mini-apps often focus on HPC; there is room for more ",["$","em",null,{"children":"data-centric"}]," mini-apps (AI analytics, graph mining) geared toward memory system evaluation."]}]
3c:["$","h2",null,{"className":"content-header","id":"4-memory-observability-and-profiling-tools","children":[["$","a",null,{"className":"break-words","href":"#4-memory-observability-and-profiling-tools","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],["$","strong",null,{"children":"4. Memory Observability and Profiling Tools"}]]}]
3d:["$","p",null,{"children":"Observability tools monitor and profile memory usage in real time, either via software instrumentation or hardware performance counters. Recent tools emphasize low overhead and fine-grained insight (e.g., which data structures cause cache misses, or how NUMA latency affects a workload):"}]
3e:["$","ul",null,{"children":[["$","li",null,{"children":[["$","strong",null,{"children":["Linux ",["$","code",null,{"children":"perf"}]," and PMUs (ongoing)"]}]," – The ubiquitous ",["$","strong",null,{"children":"perf"}]," tool leverages on-chip Performance Monitoring Units to track events like cache misses, memory bandwidth, and even memory load addresses (with Intel PEBS). Over the last few years, enhancements include ",["$","strong",null,{"children":"offcore response counters"}]," (to measure memory latency distribution) and ",["$","strong",null,{"children":"TopDown metrics"}]," that show bound stalls (memory-bound vs CPU-bound). While not a new tool, ",["$","strong",null,{"children":["$","code",null,{"children":"perf"}]}]," underpins many higher-level profilers and has gained support for profiling new memory tech (e.g., counting Optane media reads vs. writes on Ice Lake SP)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Intel VTune & AMD uProf (2018–2025 updates)"}]," – These vendor GUI profilers provide advanced memory analysis: e.g., VTune’s Memory Access analysis can attribute cache misses and DRAM bandwidth to source code and data structures. AMD uProf similarly has cache sampling. They use hardware features like Intel PEBS Load Latency and AMD IBS to sample the ",["$","em",null,{"children":"memory addresses"}]," causing the longest latencies. These tools have been updated to handle ",["$","strong",null,{"children":"persistent memory"}]," (showing PMem vs DRAM traffic) and ",["$","strong",null,{"children":"CXL"}]," (on supporting platforms, to identify remote memory access penalties). ",["$","em",null,{"children":"Limitation:"}]," They are proprietary and sometimes struggle with kernel-space or multi-tenant observability."]}],["$","li",null,{"children":[["$","strong",null,{"children":"MemAxes (LLNL, 2015 & updates)"}]," – An ",["$","strong",null,{"children":"interactive visualization"}]," tool for memory performance data. MemAxes takes samples of memory accesses (from Intel PEBS or AMD IBS which capture load addresses and latency) and provides multiple coordinated views: hardware topology (e.g., heatmaps of NUMA node traffic), source code lines (“top offenders” in memory stalls), data structure address space, and parallel timelines. By clicking on a cache or a line of code, the user can see where memory hot-spots occur. MemAxes was used to diagnose NUMA issues (visualizing that certain threads accessed remote memory heavily) and cache coherence bottlenecks. ",["$","em",null,{"children":"Platform:"}]," x86, works with sampled profiles. This tool exemplifies how ",["$","strong",null,{"children":"visual analytics"}]," can make sense of complex memory performance data."]}],["$","li",null,{"children":[["$","strong",null,{"children":"LIKWID (Open-source, v5 2021)"}]," – A command-line toolkit for on-node performance monitoring. LIKWID’s ",["$","strong",null,{"children":["$","code",null,{"children":"mem"}]}]," and ",["$","strong",null,{"children":["$","code",null,{"children":"cache"}]}]," modules can measure memory bandwidth (using hardware counter events) and visualize NUMA bandwidth, latency, and LLC misses in real time. It simplifies counter usage (no manual event programming). LIKWID is popular in HPC for quick memory bottleneck checks, e.g., measuring memory bandwidth per socket while tuning NUMA affinity. ",["$","em",null,{"children":"Limitation:"}]," Limited to what hardware counters can measure; it won’t show ",["$","em",null,{"children":"which code"}]," caused the misses (complementary to profilers like VTune)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Intel Memory Latency Checker (MLC)"}]," – A specialized tool from Intel to measure ","$L60"," under various access patterns","$L61",". MLC runs microbenchmarks (pointer chasing, read vs write mixes) and reports a matrix of local vs remote latency, bandwidth curves for different read/write ratios, etc.","$L62",". Updated in 2024, it supports testing with hardware prefetchers on/off and works on Linux/Windows","$L63","$L64",". MLC is widely used to baseline NUMA latency and memory throughput on new servers. ","$L65"," It’s a synthetic test – real app behavior may differ (MLC cannot tell which workload is memory-bound; it only gives hardware capabilities)."]}],"$L66","$L67"]}]
3f:["$","p",null,{"children":[["$","strong",null,{"children":"Trend:"}]," The convergence of ",["$","strong",null,{"children":"hardware counter data"}]," with ",["$","strong",null,{"children":"intelligent analytics/visualization"}]," is a big theme. We moved from simply counting misses to attributing them to code (PEBS sampling, IBS) and even visualizing across system topology (MemAxes). Another pattern is ",["$","strong",null,{"children":"integrating profiling with benchmarking"}],": tools like the MESS framework (next section) position applications on a “memory bandwidth–latency” curve to summarize their memory demands",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://arxiv.org/html/2405.10170v1#:~:text=The%20Mess%20benchmark%20provides%20a,closely%20matches%20the%20actual%20system","children":"arxiv.org"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://arxiv.org/html/2405.10170v1#:~:text=The%20current%20Mess%20benchmark%20release,production%20HPC%20performance%20analysis%20tools","children":"arxiv.org"}],". A challenge remains in profiling ",["$","strong",null,{"children":"heterogeneous memory"}]," usage – e.g., if data is spread across DRAM and NVM, current profilers have limited insight into ",["$","em",null,{"children":"which memory"}]," was accessed unless special events or drivers are used. This is an open problem: more work is needed on tools that can attribute memory accesses to different tiers (e.g., a combined CPU+FPGA memory profiler, or tracking CXL memory accesses in CPU profiles). Also, as memory systems get more complex (consider encrypted memory, or chiplet-based memory), observability might require new hardware support – an opportunity for co-designing profiling features in future CPUs."]}]
40:["$","h2",null,{"className":"content-header","id":"5-tools-for-heterogeneous-memory-systems-cxl-hbm-pmem-etc","children":[["$","a",null,{"className":"break-words","href":"#5-tools-for-heterogeneous-memory-systems-cxl-hbm-pmem-etc","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],["$","strong",null,{"children":"5. Tools for Heterogeneous Memory Systems (CXL, HBM, PMEM, etc.)"}]]}]
41:["$","p",null,{"children":"Heterogeneous memory systems combine different technologies (DDR DRAM, high-bandwidth memory, persistent memory, disaggregated memory via CXL). Tools in this space aim to evaluate and manage such complex hierarchies:"}]
42:["$","ul",null,{"children":[["$","li",null,{"children":[["$","strong",null,{"children":"MESS Framework (Esmaili et al., 2024)"}]," – A comprehensive framework for memory ",["$","strong",null,{"children":"benchmarking, simulation, and profiling"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://arxiv.org/html/2405.10170v1#:~:text=The%20Mess%20benchmark%20provides%20a,closely%20matches%20the%20actual%20system","children":"arxiv.org"}],". MESS provides: (a) the ",["$","strong",null,{"children":"Mess Benchmark"}],", which empirically measures a system’s full memory ",["$","em",null,{"children":"bandwidth vs. latency curve"}]," under various read/write mixes",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://arxiv.org/html/2405.10170v1#:~:text=The%20Mess%20benchmark%20provides%20a,end%20memory%20technologies.%20The%20Mess","children":"arxiv.org"}],"; (b) the ",["$","strong",null,{"children":"Mess Simulator"}],", which integrates this empirically derived memory model into CPU simulators (gem5, ZSim, OpenPiton) for accurate memory timing; (c) ",["$","strong",null,{"children":"Mess Application Profiling"}],", which plots real apps onto the bandwidth-latency space. Crucially, Mess covers ",["$","strong",null,{"children":"all major memory tech"}]," – DDR4/5, Optane DC PMem, HBM2/2E, and even CXL 1.1 memory expanders. For example, it can characterize an Intel Skylake with DDR4 vs. Fujitsu A64FX with HBM2, showing how HBM’s bandwidth benefits are offset by latency differences",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://arxiv.org/html/2405.10170v1#:~:text=Table%C2%A0I%20while%20Figure%C2%A03%20shows%20their,This","children":"arxiv.org"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://arxiv.org/html/2405.10170v1#:~:text=ranges%20from%2085%20ns%20in,This","children":"arxiv.org"}],". The open-source Mess simulator allows quick adoption of new memory devices in architecture research (just plug in the measured curves). ",["$","em",null,{"children":"Key finding:"}]," Mess revealed that many simulators (gem5, ZSim) were ",["$","strong",null,{"children":"over-optimistic"}]," about memory, e.g., assuming unrealistically low latencies or too-high bandwidth. By integrating real measurements, simulation error dropped to ~1–3%. ",["$","em",null,{"children":"Usage barrier:"}]," Requires access to real hardware to get the initial calibration; also, the benchmark runs many micro-tests, taking time on large systems."]}],["$","li",null,{"children":[["$","strong",null,{"children":"DRAMSim3 and Ramulator (2020)"}]," – These are ",["$","strong",null,{"children":"memory system simulators"}]," that have added support for new memory types. DRAMSim3 (UMD) and Ramulator (CMU) can model GDDR, HBM, LPDDR, and basic NVM timing. While not full “tools” by themselves, they are often integrated into frameworks (e.g., ZSim+Ramulator used in Mess to simulate advanced memories",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://ar5iv.labs.arxiv.org/html/2405.10170v1#:~:text=Image%3A%20Refer%20to%20caption%20,ZSim%3A%20M%2FD%2F1%20Queue%20model","children":"ar5iv.labs.arxiv.org"}],"). They allow evaluating new devices (like HBM3 or DDR5) in isolation. ",["$","em",null,{"children":"Limitation:"}]," They require workloads or traces as input – often used in conjunction with the synthetic and trace tools discussed above."]}],["$","li",null,{"children":[["$","strong",null,{"children":"DRackSim (Amit Puri et al., 2023)"}]," – A simulator specifically for ","$L68"," (e.g., memory pooled via CXL). DRackSim models multiple compute nodes connected to memory pool devices over a CXL/Gen-Z-like fabric. It includes an out-of-order core and caches at each node, a network fabric model with latency and bandwidth, and a centralized memory manager for address translation. Uniquely, it supports both ","$L69"," (memory cached transparently) and ","$L6a"," to remote memory, reflecting different CXL usage models. DRackSim uses DRAMSim2 internally to simulate memory timing for each pool and can evaluate policies like when to cache remote memory vs. direct access. In experiments, it quantified performance impact of different ratios of local vs. remote memory for HPC workloads (showing, for example, a 20–30% penalty when a significant fraction of memory is remote over CXL for memory-bound MPI codes). ","$L6b"," As a simulation, accuracy depends on the provided network and device parameters; real CXL hardware is just emerging for validation."]}],"$L6c","$L6d","$L6e"]}]
43:["$","p",null,{"children":[["$","strong",null,{"children":"Trend:"}]," The rush of new memory tech in the last 5 years (NVM, CXL, HBM) has led to ",["$","em",null,{"children":"many specialized tools"}],", often created alongside the first papers on those technologies. A consistent pattern is the use of ",["$","strong",null,{"children":"simulation combined with measurement"}]," – because hardware often lags. For example, before CXL hardware was widely available, researchers built simulators like DRackSim or used QEMU-based emulators. Now that CXL memory expanders are appearing (2023+), we might see more empirical benchmarks and profiling of those (the Mess framework already has an experimental CXL ",["$","em",null,{"children":"remote socket emulation"}]," that uses one server’s NUMA node to emulate a CXL device)."]}]
44:["$","p",null,{"children":["A notable gap is ",["$","strong",null,{"children":"integration"}],": currently, one needs to use separate tools for each tier (one for HBM on GPU, another for PMem, etc.). The Mess framework is a step toward integration by providing a unified performance view. There is an open opportunity to develop a ",["$","em",null,{"children":"unified heterogeneous memory benchmark suite"}]," (as noted in Section 3) and an integrated profiler that can, say, concurrently track DRAM, HBM, and NVM usage in a running program. Additionally, ",["$","strong",null,{"children":"co-design tools"}]," are needed: e.g., to jointly simulate a new memory controller and evaluate it with realistic heterogeneous workloads (current simulators like gem5 can attach simple “fast” and “slow” memory, but tuning algorithms for moving data between tiers is still ad hoc). Future work may involve AI-driven data placement tools (learn an application’s access patterns and automatically partition data across tiers), which will require new benchmarking methodologies to fairly compare such intelligent systems."]}]
45:["$","h2",null,{"className":"content-header","id":"6-compiler-and-runtime-approaches-to-memory-stress-modeling","children":[["$","a",null,{"className":"break-words","href":"#6-compiler-and-runtime-approaches-to-memory-stress-modeling","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],["$","strong",null,{"children":"6. Compiler and Runtime Approaches to Memory Stress Modeling"}]]}]
46:["$","p",null,{"children":"Beyond standalone tools, compilers and runtime systems can generate or manipulate code to model memory stress patterns. These approaches embed memory stress into programs or adjust execution to emulate certain memory behaviors:"}]
47:["$","ul",null,{"children":[["$","li",null,{"children":[["$","strong",null,{"children":"FIRESTARTER 2 (TUD 2018)"}]," – A dynamic code generation toolkit originally for CPU ",["$","em",null,{"children":"thermal stress"}],", but highly relevant to memory stress testing. FIRESTARTER uses templates to emit loops with controlled instruction mix, loop unrolling, and memory access patterns. One can specify the ",["$","strong",null,{"children":"memory level"}]," to target (L1, L2, L3, or RAM) and the type of accesses (loads, stores, load+store, etc.) and FIRESTARTER will generate code accordingly. For example, to stress main memory, it might generate a pointer-chasing load every few instructions, ensuring the working set exceeds LLC. By tuning the unroll factor, it ensures the CPU front-end isn’t the bottleneck (so stalls come from memory). This approach effectively creates a ",["$","em",null,{"children":"parameterized memory stress benchmark"}]," via the compiler. ",["$","em",null,{"children":"Use cases:"}]," hardware bring-up (generate worst-case memory traffic), or creating custom stress tests (like a workload that simulates 70% reads, 30% writes to RAM with certain stride)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Automated Loop Transformations:"}]," Modern compilers (GCC, LLVM) include analyses to improve memory access patterns (e.g., loop interchange, blocking for locality). Some research flips this around – using compilers to ",["$","em",null,{"children":"generate worst-case patterns"}],". For instance, one can write a compiler pass that reorders loops to produce either ",["$","em",null,{"children":"sequential"}]," or ",["$","em",null,{"children":"strided"}]," memory access as needed for experiments. There was work on “jitter” benchmarks where the compiler injected delay or dummy memory ops to simulate slower memory. While not a single known tool, these techniques appear in research when evaluating, say, how performance changes if memory was 2× slower – a compiler can insert dummy computations or scale memory latency in simulation."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Runtime Page Migration Simulators:"}]," A few works (e.g., ",["$","strong",null,{"children":"SoftNUMA, 2020"}],") instrument memory allocations and insert calls to simulate memory tiering at runtime. For example, a runtime could intercept allocations and randomly assign some to “slow memory” (backed by an array that incurs extra delay on access) to mimic a percentage of PMem usage. This is a bit crude but has been used to evaluate OS strategies without actual NVM hardware – essentially, compiler or runtime wrappers that artificially slow down certain allocations to model heterogeneous memory. Tools like ",["$","strong",null,{"children":"numactl"}]," with the Linux ",["$","strong",null,{"children":["$","code",null,{"children":"mmap(MAP_HUGETLB|MAP_PRIVATE|…)"}]}]," and ",["$","strong",null,{"children":["$","code",null,{"children":"mprotect"}]}]," tricks have been used to emulate slower memory by diffusing an app’s memory across NUMA nodes or inserting software pauses on access faults (a technique seen in some academic experiments)."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Workload Shaping via Compiler"}]," – There is research on using compiler analysis to extract memory access characteristics of an app and then ",["$","em",null,{"children":"synthesize a smaller code"}]," that has similar characteristics. This is similar to shadow workloads (Section 1) but at compile-time. For example, MIT’s ",["$","strong",null,{"children":"PerfFusion (2021)"}]," composes pieces of code (each stressing memory in a certain way) to mimic a target workload’s performance counters. It uses compiler IR to understand memory intensity and then generates a fused proxy. Such approaches blur the line between compilers and benchmarking tools – the compiler becomes a tool to ","$L6f"," a benchmark given a performance profile."]}],"$L70"]}]
48:["$","p",null,{"children":[["$","strong",null,{"children":"Trend:"}]," The compiler/runtime approach is all about ",["$","strong",null,{"children":"control and automation"}]," – having the program itself (or the system software) generate the memory accesses needed for evaluation. It complements explicit benchmarks by enabling ",["$","em",null,{"children":"fine-grained tailoring"}],". A modern example is using LLVM’s ",["$","strong",null,{"children":["$","code",null,{"children":"llvm-mca"}]}]," to predict how a sequence of memory ops will execute on a microarchitecture, then automatically generating code to either maximize memory pressure or simulate a particular miss rate. This area is arguably underutilized – many evaluations still rely on fixed benchmarks, whereas a compiler-driven approach could produce ",["$","em",null,{"children":"a spectrum of memory stresses"}]," (e.g., a continuum from very cache-friendly to very cache-unfriendly code) for more systematic studies."]}]
49:["$","p",null,{"children":["One open opportunity is to integrate these approaches with emerging ",["$","strong",null,{"children":"portable APIs"}]," – for example, using OpenMP or SYCL to allocate arrays in different memory spaces (like GPU HBM or host DDR) and then auto-generate tests that move data among them. Compilers could also automatically inject ",["$","strong",null,{"children":"instrumentation or throttling"}]," to mimic future memory devices. For instance, to anticipate ",["$","em",null,{"children":"CMOS Storage Class Memory"}]," latencies, a compiler pass might add a calibrated delay loop on each memory load in a region of code – effectively “compiling in” a memory slowdown factor. Such techniques could enable proactive evaluation of hardware that isn’t even built yet, using today’s machines."]}]
4a:["$","h2",null,{"className":"content-header","id":"7-research-gaps-and-open-opportunities","children":[["$","a",null,{"className":"break-words","href":"#7-research-gaps-and-open-opportunities","aria-hidden":"true","tabIndex":"-1","children":["$","span",null,{"className":"content-header-link","children":["$","svg",null,{"className":"h-5 linkicon w-5","fill":"currentColor","viewBox":"0 0 20 20","xmlns":"http://www.w3.org/2000/svg","children":[["$","path",null,{"d":"M12.232 4.232a2.5 2.5 0 0 1 3.536 3.536l-1.225 1.224a.75.75 0 0 0 1.061 1.06l1.224-1.224a4 4 0 0 0-5.656-5.656l-3 3a4 4 0 0 0 .225 5.865.75.75 0 0 0 .977-1.138 2.5 2.5 0 0 1-.142-3.667l3-3Z"}],["$","path",null,{"d":"M11.603 7.963a.75.75 0 0 0-.977 1.138 2.5 2.5 0 0 1 .142 3.667l-3 3a2.5 2.5 0 0 1-3.536-3.536l1.225-1.224a.75.75 0 0 0-1.061-1.06l-1.224 1.224a4 4 0 1 0 5.656 5.656l3-3a4 4 0 0 0-.225-5.865Z"}]]}]}]}],["$","strong",null,{"children":"7. Research Gaps and Open Opportunities"}]]}]
4b:["$","p",null,{"children":"Surveying these tools and projects reveals several clear gaps and opportunities in the landscape of memory workload generation and evaluation:"}]
4c:["$","ul",null,{"children":[["$","li",null,{"children":[["$","strong",null,{"children":"Unified Frameworks:"}]," There is a lack of an ",["$","em",null,{"children":"integrated framework"}]," that spans ",["$","strong",null,{"children":"benchmarking, tracing, simulation, and profiling"}]," in one. Researchers often piece together disparate tools – one for trace capture, another for simulation, others for analysis – which is labor-intensive and error-prone. The MESS framework’s unified bandwidth-latency approach is a step in this direction",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://arxiv.org/html/2405.10170v1#:~:text=The%20Mess%20benchmark%20provides%20a,closely%20matches%20the%20actual%20system","children":"arxiv.org"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://arxiv.org/html/2405.10170v1#:~:text=The%20current%20Mess%20benchmark%20release,production%20HPC%20performance%20analysis%20tools","children":"arxiv.org"}],". An open opportunity is to create a coherent toolkit where the same workload description can be: ",["$","em",null,{"children":"generated"}]," synthetically, ",["$","em",null,{"children":"replayed"}]," in simulation, ",["$","em",null,{"children":"run"}]," on real hardware, and ",["$","em",null,{"children":"profiled"}]," – with results comparable across these modes. This would greatly ease ",["$","strong",null,{"children":"memory system co-design"}],", letting architects and software developers iterate together."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Coverage of Emerging Technologies:"}]," Many tools are still catching up to new memory tech. For example, ",["$","strong",null,{"children":"Compute Express Link (CXL)"}]," attached memory is very new – aside from DRackSim and some vendor eval kits, not many open tools exist. As CXL 2.0/3.0 bring memory pooling and sharing, we need benchmarks and profilers that can generate ",["$","strong",null,{"children":"CXL-specific traffic patterns"}]," (like lots of random remote accesses, or flush/fence patterns for coherency). Similarly, ",["$","strong",null,{"children":"unified memory"}]," in CPU–GPU systems (e.g., AMD’s Infinity Fabric, NVIDIA’s UVM) blurs the line between local and remote memory – current benchmarks don’t explicitly test behavior like its paging or migration overhead. Developing mini-apps and microbenchmarks that specifically target ",["$","em",null,{"children":"memory migration, fabric latency, and coherence across CXL/unified memory"}]," is an open area."]}],["$","li",null,{"children":[["$","strong",null,{"children":"Cross-Domain Workloads:"}]," Real workloads increasingly span domains – consider an AI analytics pipeline that uses CPU DRAM, GPU HBM, and maybe spills to NVM. Today’s tools typically focus on one domain (GPU or CPU or storage). There’s a gap in ",["$","strong",null,{"children":"trace and proxy tools for combined workloads"}],". For instance, a trace that captures CPU and GPU memory references together (perhaps GLTraceSim could evolve in this direction) would help design shared memory systems. Another example: no standard way exists to replay a ",["$","strong",null,{"children":"full cloud application’s memory access"}]," across distributed nodes (Ditto begins to address full-app cloning, but memory traces across networked services remain largely uncharted). Future research could create “full-stack” memory workload generators that include network and storage accesses, giving a holistic view of memory system demands in distributed applications."]}],["$","li",null,{"children":["$L71"," Many academic tools (especially simulators and cloning frameworks) have steep learning curves or are not maintained. This creates a barrier for practitioners. There is an opportunity for the community to invest in ","$L72"," that package these advanced techniques behind simpler interfaces. For example, a web-based service where a user can upload a binary or trace and request a synthetic clone or memory simulation results. Or integrating memory profiling visualizations (like MemAxes) into popular performance analysis GUIs to broaden adoption. The more accessible these tools, the more real-world impact on system design they will have."]}],"$L73","$L74"]}]
4d:["$","p",null,{"children":["In summary, the past five years have significantly advanced our toolkit for memory system evaluation – from smarter synthetic generators and proxy benchmarks to more holistic simulators and profilers – particularly to handle new technologies like persistent and disaggregated memory. Yet, the landscape is still fragmented. By bridging these tools and addressing the above gaps, researchers can better tackle the growing complexity of memory systems. The ultimate vision is a set of ",["$","em",null,{"children":"seamlessly integrated, AI-assisted"}]," tools that can take an arbitrary workload and ",["$","strong",null,{"children":"characterize, clone, stress-test, and co-design"}]," the memory system with minimal manual effort. Achieving that will empower designers to keep pace with the rapidly evolving memory hierarchy and ensure that future hardware and software are optimized in tandem for memory performance."]}]
4e:["$","p",null,{"children":["$","strong",null,{"children":"Sources:"}]}]
4f:["$","ol",null,{"children":[["$","li",null,{"children":["Shi et al., “Memory Workload Synthesis Using Generative AI,” ",["$","em",null,{"children":"MemSys 2023"}]]}],["$","li",null,{"children":["Balakrishnan & Solihin, “WEST: Cloning Data Cache Behavior using Stochastic Traces,” ",["$","em",null,{"children":"HPCA 2012"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.researchgate.net/publication/241627523_WEST_Cloning_data_cache_behavior_using_Stochastic_Traces#:~:text=replicating%20data%20cache%20behavior,We%20evaluated","children":"researchgate.net"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.researchgate.net/publication/241627523_WEST_Cloning_data_cache_behavior_using_Stochastic_Traces#:~:text=IPC%20model%20to%20control%20the,for%20over%20600%20configurations","children":"researchgate.net"}]]}],["$","li",null,{"children":["Awad & Solihin, “STM: Cloning the Spatial and Temporal Memory Access Behavior,” ",["$","em",null,{"children":"HPCA 2014"}]]}],["$","li",null,{"children":["Balakrishnan & Solihin, “MEMST: Cloning Memory Behavior using Stochastic Traces,” ",["$","em",null,{"children":"MemSys 2015"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://dl.acm.org/doi/10.1145/2818950.2818971#:~:text=We%20propose%20Memory%20EMulation%20using,capturing%20DRAM%20and%20MC%20behavior","children":"dl.acm.org"}]]}],["$","li",null,{"children":["Panda & John, “Proxy Benchmarks for Emerging Big-Data Workloads (PerfProx),” ",["$","em",null,{"children":"PACT 2017"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://lca.ece.utexas.edu/pubs/pact_camready_MJ_fin.pdf#:~:text=complex%2C%20long,using%20performance%20metrics%20derived%20primarily","children":"lca.ece.utexas.edu"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://lca.ece.utexas.edu/pubs/pact_camready_MJ_fin.pdf#:~:text=on%20different%20hardware%20platforms%20and,management%20has%20become%20an%20integral","children":"lca.ece.utexas.edu"}]]}],["$","li",null,{"children":["Panda & John, “HALO: Hierarchical Memory Access Locality Modeling,” ",["$","em",null,{"children":"MemSys 2018"}]]}],["$","li",null,{"children":["Ahmed et al., “Fine Grained Shadow Workload Generation Preserving Memory Access Patterns,” ",["$","em",null,{"children":"Univ. of Virginia Tech Report 2021"}]]}],["$","li",null,{"children":["Liang et al., “Ditto: End-to-End Application Cloning for Cloud Services,” ",["$","em",null,{"children":"ASPLOS 2023"}]," (preprint)"]}],["$","li",null,{"children":["Esmaili-Dokht et al., “A MESS of Memory System Benchmarking…,” ",["$","em",null,{"children":"arXiv 2024"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://arxiv.org/html/2405.10170v1#:~:text=The%20Mess%20benchmark%20provides%20a,closely%20matches%20the%20actual%20system","children":"arxiv.org"}]]}],["$","li",null,{"children":["Puri et al., “DRackSim: Simulator for Rack-scale Memory Disaggregation,” ",["$","em",null,{"children":"arXiv 2023"}]]}],["$","li",null,{"children":["Benson et al., “PerMA-Bench: Benchmarking Persistent Memory Access,” ",["$","em",null,{"children":"PVLDB 2022"}]]}],["$","li",null,{"children":"GitHub – LLNL/MemAxes (Memory Access Visualization Tool)"}],["$","li",null,{"children":["Intel Corp., “Intel® Memory Latency Checker v3.11,” 2024",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html#:~:text=Intel%C2%AE%20Memory%20Latency%20Checker%20,can%20be%20measured%20as%20well","children":"intel.com"}]]}],["$","li",null,{"children":"GitHub – uart/GLTraceSim (CPU+GPU Memory Trace Framework)"}],"$L75","$L76","$L77","$L78","$L79","$L7a","$L7b","$L7c","$L7d"]}]
50:["$","div",null,{"className":"pt-6 pb-6 text-sm text-gray-700 dark:text-gray-300 glass p-4 rounded-xl","children":[["$","a",null,{"className":"hover:text-primary-600 dark:hover:text-primary-400 transition-colors","target":"_blank","rel":"nofollow","href":"https://mobile.twitter.com/search?q=https%3A%2F%2Fwww.yunwei37.com%2Fblog%2Fcxlmemtest","children":"Discuss on Twitter"}]," • ",["$","a",null,{"className":"hover:text-primary-600 dark:hover:text-primary-400 transition-colors","target":"_blank","rel":"noopener noreferrer","href":"https://github.com/yunwei37/yunwei37-blog/blob/main/data/blog/cxlmemtest.mdx","children":"View on GitHub"}]]}]
51:["$","div",null,{"className":"pt-6 pb-6 text-center text-gray-700 dark:text-gray-300 glass p-6 rounded-xl","id":"comment","children":["$","$L7e",null,{"slug":"cxlmemtest"}]}]
52:["$","footer",null,{"children":[["$","div",null,{"className":"divide-gray-200/30 text-sm leading-5 font-medium xl:col-start-1 xl:row-start-2 xl:divide-y dark:divide-gray-700/30","children":[["$","div",null,{"className":"py-4 xl:py-8","children":[["$","h2",null,{"className":"text-xs tracking-wide text-gray-600 uppercase dark:text-gray-300 mb-4","children":"Tags"}],["$","div",null,{"className":"flex flex-wrap gap-2","children":[["$","$L6","ebpf",{"href":"/tags/ebpf","className":"inline-block px-3 py-1 text-xs font-medium uppercase tracking-wide bg-primary-100 hover:bg-primary-200 dark:bg-primary-900/30 dark:hover:bg-primary-800/40 rounded-full transition-all duration-200 text-primary-800 hover:text-primary-900 dark:text-primary-300 dark:hover:text-primary-200 border border-primary-200/50 dark:border-primary-700/50","children":"ebpf"}],["$","$L6","systems",{"href":"/tags/systems","className":"inline-block px-3 py-1 text-xs font-medium uppercase tracking-wide bg-primary-100 hover:bg-primary-200 dark:bg-primary-900/30 dark:hover:bg-primary-800/40 rounded-full transition-all duration-200 text-primary-800 hover:text-primary-900 dark:text-primary-300 dark:hover:text-primary-200 border border-primary-200/50 dark:border-primary-700/50","children":"systems"}]]}]]}],["$","div",null,{"className":"flex justify-between py-4 xl:block xl:space-y-6 xl:py-8","children":[["$","div",null,{"className":"glass p-4 rounded-xl","children":[["$","h2",null,{"className":"text-xs tracking-wide text-gray-600 uppercase dark:text-gray-300 mb-2","children":"Previous Article"}],["$","div",null,{"className":"text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 transition-colors","children":["$","$L6",null,{"className":"break-words","href":"/blog/osdi-sosp-obser-debug","children":"**Observability, Profiling, and Debugging in Systems Conference (2015–2025)**"}]}]]}],["$","div",null,{"className":"glass p-4 rounded-xl","children":[["$","h2",null,{"className":"text-xs tracking-wide text-gray-600 uppercase dark:text-gray-300 mb-2","children":"Next Article"}],["$","div",null,{"className":"text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 transition-colors","children":["$","$L6",null,{"className":"break-words","href":"/blog/profile-tools-limitation","children":"Profiling and Tracing Tools Across System Layers and Architectures"}]}]]}]]}]]}],["$","div",null,{"className":"pt-4 xl:pt-8","children":["$","$L6",null,{"className":"inline-flex items-center glass px-4 py-2 rounded-xl text-primary-600 hover:text-primary-700 dark:text-primary-400 dark:hover:text-primary-300 transition-all duration-200 hover:scale-105","href":"/blog","aria-label":"Back to the blog","children":"← Back to the blog"}]}]]}]
53:["$","li",null,{"children":[["$","strong",null,{"children":"HALO (MEMSYS 2018)"}]," – ",["$","em",null,{"children":"Hierarchical Access Locality Modeling"}]," groups memory references into localized streams to capture patterns per data region. HALO’s statistically generated clones reproduced L1, L2, TLB, and DRAM performance within ~95–99% accuracy of the original, ",["$","strong",null,{"children":"outperforming"}]," prior schemes (WEST, STM) and using ~39× less metadata. It proved effective even with prefetchers enabled, by modeling inter-stream interleaving."]}]
54:["$","li",null,{"children":[["$","strong",null,{"children":"PerfProx (PACT 2017)"}]," – A ",["$","strong",null,{"children":"proxy benchmark generation"}]," framework for emerging cloud and database workloads",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://lca.ece.utexas.edu/pubs/pact_camready_MJ_fin.pdf#:~:text=complex%2C%20long,using%20performance%20metrics%20derived%20primarily","children":"lca.ece.utexas.edu"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://lca.ece.utexas.edu/pubs/pact_camready_MJ_fin.pdf#:~:text=on%20different%20hardware%20platforms%20and,management%20has%20become%20an%20integral","children":"lca.ece.utexas.edu"}],". PerfProx rapidly produces a ",["$","em",null,{"children":"miniature benchmark"}]," that mimics a big-data application’s performance characteristics using only hardware performance counter profiles (no full instruction traces). It achieved ~94% accuracy in reproducing the IPC and cache/TLB behavior of complex MySQL, Cassandra, and MongoDB workloads",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://lca.ece.utexas.edu/pubs/pact_camready_MJ_fin.pdf#:~:text=on%20different%20hardware%20platforms%20and,management%20has%20become%20an%20integral","children":"lca.ece.utexas.edu"}],", while cutting runtime and dependencies. ",["$","em",null,{"children":"Platform:"}]," x86 Linux; ",["$","em",null,{"children":"Limitation:"}]," focuses on high-level performance metrics (IPC, misses) rather than exact memory address streams."]}]
55:["$","li",null,{"children":[["$","strong",null,{"children":"CAMP (DATE 2017)"}]," – ",["$","em",null,{"children":"Core and Memory Proxy"}]," methodology that models both CPU core and memory behavior for big-data apps (cited alongside PerfProx)",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.researchgate.net/publication/241627523_WEST_Cloning_data_cache_behavior_using_Stochastic_Traces#:~:text=,","children":"researchgate.net"}],". CAMP uses a statistical approach to synthesize proxies that capture ",["$","strong",null,{"children":"coordinated"}]," core utilization and memory access patterns."]}]
56:["$","li",null,{"children":[["$","strong",null,{"children":"“Shadow” Workload Generation (2018–2021)"}]," – Recent research (Alif Ahmed et al.) proposes automated ",["$","em",null,{"children":"flow-graph compression"}]," of program traces to produce portable ",["$","strong",null,{"children":"shadow workloads"}],". These clones preserve phase behavior and are ISA-agnostic. For example, the tool identifies the top memory-accessing instructions, records their execution trace, compresses it, and generates a small clone program. On evaluated benchmarks, the shadow’s L2 cache misses were within 1.85% of the original and tracked performance trends across different memory configurations (correlation 0.94+). ",["$","em",null,{"children":"Limitation:"}]," Requires binary instrumentation and trace collection from the original app."]}]
57:["$","li",null,{"children":[["$","strong",null,{"children":"Generative AI Workload Synthesis (Memsys 2023)"}]," – A novel approach uses ",["$","strong",null,{"children":"transformer models"}]," (inspired by GPT) to learn memory access sequences and generate synthetic traces. By training on program traces, the generative model outputs new address sequences that statistically resemble the original in both short-range (latency-sensitive) and long-range reuse patterns. The authors show AI-generated traces can match or exceed the accuracy of traditional statistical methods given proper post-processing. ",["$","em",null,{"children":"This is the first use of deep generative models for memory workload cloning."}]," ",["$","em",null,{"children":"Limitation:"}]," Ensuring the model doesn’t produce unrealistic or insecure patterns (the approach is still experimental)."]}]
58:["$","li",null,{"children":[["$","strong",null,{"children":"Ditto (ASPLOS 2023 preprint)"}]," – An ",["$","em",null,{"children":"end-to-end application cloning"}]," framework for distributed cloud microservices. While not memory-specific, Ditto captures an entire application’s behavior (CPU, memory, I/O, network, system calls) and generates a faithful clone that can be openly shared. It uses a hierarchical approach (service dependency graph → per-service control flow → synthetic code) to recreate complex workloads (including memory usage) without exposing proprietary code. Ditto accurately reproduces memory and CPU usage patterns of multi-tier cloud apps. ",["$","em",null,{"children":"Opportunity:"}]," Techniques like Ditto could be extended to memory subsystem co-design, by enabling vendors to evaluate memory hardware with clones of real software stacks."]}]
59:["$","strong",null,{"children":"GLTraceSim"}]
5a:["$","em",null,{"children":"Platforms:"}]
5b:["$","em",null,{"children":"Use case:"}]
5c:["$","li",null,{"children":[["$","strong",null,{"children":"Frameworks for I/O and Storage Traces:"}]," (Though beyond main memory, they intersect with memory systems.) Tools like ",["$","strong",null,{"children":"ReAnimator"}]," (Stony Brook, 2017) capture full-system storage traces and replay them to test file system caches. Similarly, the ",["$","strong",null,{"children":"TBBT"}]," and ",["$","strong",null,{"children":"HDTrace"}]," tools can scale I/O traces for “what-if” evaluations. These influence how memory paging and cache behavior are replayed under heavy I/O workloads."]}]
5d:["$","em",null,{"children":"CloverLeaf"}]
5e:["$","li",null,{"children":[["$","strong",null,{"children":"Persistent Memory Benchmarks:"}]," With the advent of Intel Optane DC Persistent Memory (2019–2020), new benchmarks emerged to test ",["$","strong",null,{"children":"NVDIMM"}]," performance. One is ",["$","strong",null,{"children":"PerMA-Bench (PVLDB 2022)"}],", a configurable benchmark framework for persistent memory. PerMA-Bench provides a suite of micro-operations (sequential vs. random reads/writes, mixed workloads, pointer lookups, etc.) targeting PMem and allows users to measure bandwidth, latency, and IOPS under various configurations. Using PerMA-Bench, researchers compared first-gen and second-gen Optane DIMMs across multiple servers, revealing aspects like: read vs write asymmetry, NUMA effects with PMem, and the impact of power budgeting on PMem bandwidth. ",["$","em",null,{"children":"Limitation:"}]," Such microbenchmarks focus on ",["$","em",null,{"children":"raw device performance"}]," and simple data structures; real application performance (e.g. a database on PMem) also depends on software optimizations and access patterns that span DRAM and PMem."]}]
5f:["$","li",null,{"children":[["$","strong",null,{"children":"Hybrid Memory Workload Suites:"}]," To study tiered memory (HBM + DDR or DRAM + NVM), researchers often assemble collections of benchmarks that include ",["$","strong",null,{"children":"irregular, memory-bound codes"}],". For example, a study on HBM vs DDR performance used GUPS, Graph500, and XSBench to represent latency-sensitive workloads, and found those must reside in DRAM for best performance. Another example is the ",["$","strong",null,{"children":"HPC AI500"}]," benchmarks which include memory-hungry AI workloads to stress GPU HBM. We also see industry consortia (SPEC, TPC) considering persistent memory in their benchmarks (e.g., new versions of TPC-C for PMem storage). However, a ",["$","em",null,{"children":"unified suite"}]," that covers ",["$","em",null,{"children":"all"}]," new memory tech is still nascent."]}]
60:["$","strong",null,{"children":"memory latency and bandwidth"}]
61:["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html#:~:text=Intel%C2%AE%20Memory%20Latency%20Checker%20,can%20be%20measured%20as%20well","children":"intel.com"}]
62:["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html#:~:text=Intel%C2%AE%20Memory%20Latency%20Checker%20,can%20be%20measured%20as%20well","children":"intel.com"}]
63:["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html#:~:text=,it%20is%20not%20already%20included","children":"intel.com"}]
64:["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html#:~:text=HW%20Prefetcher%20Control","children":"intel.com"}]
65:["$","em",null,{"children":"Limitation:"}]
66:["$","li",null,{"children":[["$","strong",null,{"children":"NVIDIA Nsight Compute (2019–2025)"}]," – A GPU profiler that includes detailed memory analysis. It provides per-kernel metrics for ",["$","strong",null,{"children":"L1, L2 cache hits/misses, DRAM throughput, and shared memory usage"}],". Nsight’s guided analysis points out if a CUDA kernel is memory-bound and which memory level is the bottleneck. It effectively turns hardware counter data (like L2 transactions, DRAM bytes) into understandable guidance (e.g., “L2 cache thrashing, consider changing access pattern”). Nsight can also ",["$","strong",null,{"children":"visualize memory transactions over time"}]," within a kernel (though with overhead). This has been crucial as GPUs with HBM2/HBM3 have very high bandwidth but also non-trivial caching behavior; developers rely on Nsight to optimize memory accesses. ",["$","em",null,{"children":"Limitation:"}]," GPU-specific; also, profiling may perturb timing for very fine-grained kernels."]}]
67:["$","li",null,{"children":[["$","strong",null,{"children":"eBPF-Based Observability (emerging)"}]," – Recent Linux kernel improvements and tools like ",["$","strong",null,{"children":"bcc/eBPF"}]," allow lightweight in-production monitoring of memory events. For instance, Facebook’s ",["$","strong",null,{"children":"MemLeak"}]," and ",["$","strong",null,{"children":"Cachetop"}]," bcc tools can track slab allocations or page cache hits in real time. While not giving per-instruction detail, they help observe memory usage patterns at the OS level (e.g., which process is causing page faults, or how many cache misses per process if PEBS is sampled to eBPF). This area is growing, though not as covered in academia – it’s an industrial trend to use eBPF for observability without heavy instrumentation."]}]
68:["$","strong",null,{"children":"rack-scale disaggregated memory"}]
69:["$","strong",null,{"children":"cache-line access"}]
6a:["$","strong",null,{"children":"page-granularity access"}]
6b:["$","em",null,{"children":"Limitation:"}]
6c:["$","li",null,{"children":[["$","strong",null,{"children":"Heterogeneous Memory Management Tools:"}]," On the software side, research projects like ",["$","strong",null,{"children":"HeteroOS (SOSP 2019)"}]," have built OS-level support for tiered memory (DRAM + NVM). HeteroOS introduced an application-transparent page scheduler that places hot pages in DRAM and cold pages in NVM, yielding up to 2× performance improvement without programmer effort",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.semanticscholar.org/paper/HeteroOS-%E2%80%94-OS-design-for-heterogeneous-memory-in-Kannan-Gavrilovska/e53f0135ec71672c78a58a8916f5b0bbcd6ec4e1#:~:text=,up%20to%202x%20performance","children":"semanticscholar.org"}],". Meanwhile, frameworks such as ",["$","strong",null,{"children":"Intel Memory Tiering (in Linux kernel)"}]," and ",["$","strong",null,{"children":"NUMA Balancing"}]," have evolved to support persistent memory as another NUMA node. These aren’t benchmarking tools per se, but they provide ",["$","em",null,{"children":"techniques"}]," (like using idle page tracking to migrate pages) that influence how one would evaluate a heterogeneous memory system – ideally, benchmarking tools must account for these OS moves."]}]
6d:["$","li",null,{"children":[["$","strong",null,{"children":"H2M (FGCS 2023)"}]," – A methodology and toolset for ",["$","strong",null,{"children":"portable data placement"}]," in heterogeneous memory. H2M provides profiling to identify an application’s memory access patterns and heuristics to suggest optimal placement on multi-tier memory (like HBM vs DDR). It tries to be portable across different systems by abstracting hardware specifics. For example, H2M can take profile data from one system and predict the best data distribution for another system’s memory configuration. It fills a need for higher-level memory management evaluation: instead of simply measuring hardware, it evaluates ",["$","em",null,{"children":"data placement strategies"}],". ",["$","em",null,{"children":"Gaps:"}]," H2M is more research prototype; integration with production runtime is needed."]}]
6e:["$","li",null,{"children":[["$","strong",null,{"children":"Persistent Memory Development Kits:"}]," Tools like ",["$","strong",null,{"children":"Intel PMDK"}]," (2018–2022) come with utilities to benchmark and observe persistent memory usage (e.g., ",["$","em",null,{"children":"pmembench"}]," for measuring NVM library operations). Academia also contributed ",["$","strong",null,{"children":"WHISPER (USENIX 2019)"}]," which analyzed real-world PMem usage and failure modes, albeit more from a reliability angle. From a performance view, one notable tool is ",["$","strong",null,{"children":"TeaBench (2020)"}]," – a transactional PMEM benchmark that stresses ordering and flush costs. These help profile how well a system’s memory subsystem handles persist operations (write combining, flush bandwidth, etc.)."]}]
6f:["$","em",null,{"children":"emit"}]
70:["$","li",null,{"children":[["$","strong",null,{"children":"Managed Runtime Stress Testing:"}]," In Java or .NET, some tools allocate and free objects in patterns to stress GC and memory. For instance, ",["$","strong",null,{"children":"DaCapo"}]," (Java benchmarks) has a ",["$","em",null,{"children":"MolDyn"}]," and ",["$","em",null,{"children":"PMD"}]," workload known to stress memory allocation and GC. Researchers sometimes modify JVMs to insert ",["$","strong",null,{"children":"GC pauses or allocation throttling"}]," to emulate memory slowdown. These aren’t widely distributed tools but appear in academic evaluations of GC or memory management policies."]}]
71:["$","strong",null,{"children":"Ease of Use and Accessibility:"}]
72:["$","strong",null,{"children":"polished, open-source platforms"}]
73:["$","li",null,{"children":[["$","strong",null,{"children":"Memory Security and Privacy Aspects:"}]," One seldom-discussed area is using these tools for ",["$","strong",null,{"children":"security"}]," – e.g., synthetic traces that mimic worst-case row buffer activation (for Rowhammer testing), or profiling tools that detect abnormal memory access patterns (potential buffer overflows or side-channel access patterns). As memory systems incorporate encryption, new “workloads” (encryption metadata overhead, integrity checks) come into play. There’s room for creating benchmarks that include those operations to evaluate their performance cost, and tools to observe memory usage in encrypted or isolated enclaves (perhaps using hardware like Intel SGX PRM as “slow memory” to simulate security overheads). This intersection of memory ",["$","em",null,{"children":"performance"}]," and ",["$","em",null,{"children":"security"}]," is relatively unexplored."]}]
74:["$","li",null,{"children":[["$","strong",null,{"children":"Co-Design of Algorithms and Memory Systems:"}]," Finally, an open research opportunity lies in co-design – for instance, ",["$","strong",null,{"children":"compiler-guided memory hardware"}],". Tools now mostly treat hardware as fixed and measure it. But what if a compiler could tell the hardware its expected access pattern (e.g., “will stream through this array”) – could hardware adapt (like turning off prefetchers or using a different caching policy)? We lack frameworks to experiment with such ideas. A co-design testbed could allow a compiler to emit hints and a simulator or FPGA-based prototype memory controller to receive them, closing the loop. This would require integrating workload generation (to produce various patterns), profiling (to gather pattern info), and flexible memory simulation (to change policies on the fly). It’s complex, but a successful platform here could inspire the next-gen ",["$","strong",null,{"children":"adaptive memory systems"}],"."]}]
75:["$","li",null,{"children":"NVIDIA Developer Forums – Nsight Compute profiling metrics (2021)"}]
76:["$","li",null,{"children":["HPC Challenge Benchmark Suite (information page)",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://hpcchallenge.org/hpcc/#:~:text=3.%20STREAM%20,GUPS","children":"hpcchallenge.org"}]]}]
77:["$","li",null,{"children":["Spatter: Gather/Scatter Memory Benchmark – ",["$","em",null,{"children":"arXiv 2019"}]]}]
78:["$","li",null,{"children":["LENS: “Characterizing & Modeling NVM Systems” – ",["$","em",null,{"children":"IEEE CAL 2020"}]]}]
79:["$","li",null,{"children":["Acun et al., “Parallel Trace Replay Tool for HPC (TraceR),” ",["$","em",null,{"children":"2015"}]]}]
7a:["$","li",null,{"children":["ComputerOrg, “Proxy Benchmarks for Big Data” (PerfProx Summary)",["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://lca.ece.utexas.edu/pubs/pact_camready_MJ_fin.pdf#:~:text=on%20different%20hardware%20platforms%20and,management%20has%20become%20an%20integral","children":"lca.ece.utexas.edu"}]]}]
7b:["$","li",null,{"children":["H2M: “Exploiting Heterogeneous Shared Memory” – ",["$","em",null,{"children":"FGCS 2023"}]]}]
7c:["$","li",null,{"children":["Yan et al., “HeteroOS: OS Design for Heterogeneous Memory,” ",["$","em",null,{"children":"SOSP 2019"}],["$","a",null,{"className":"break-words","target":"_blank","rel":"noopener noreferrer","href":"https://www.semanticscholar.org/paper/HeteroOS-%E2%80%94-OS-design-for-heterogeneous-memory-in-Kannan-Gavrilovska/e53f0135ec71672c78a58a8916f5b0bbcd6ec4e1#:~:text=,up%20to%202x%20performance","children":"semanticscholar.org"}]]}]
7d:["$","li",null,{"children":["Gracia-Morán et al., “LIKWID Performance Tools,” ",["$","em",null,{"children":"Tools for High Performance Computing 2019"}]]}]
23:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
1f:null
21:{"metadata":[["$","title","0",{"children":"**The Modern Memory Testing Arsenal -- A Complete Guide to Benchmarking Tools for Next-Gen Memory Systems** | 云微的胡思乱想"}],["$","meta","1",{"name":"robots","content":"index, follow"}],["$","meta","2",{"name":"googlebot","content":"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"}],["$","link","3",{"rel":"canonical","href":"https://www.yunwei37.com/blog/cxlmemtest"}],["$","link","4",{"rel":"alternate","type":"application/rss+xml","href":"https://www.yunwei37.com/feed.xml"}],["$","meta","5",{"property":"og:title","content":"**The Modern Memory Testing Arsenal -- A Complete Guide to Benchmarking Tools for Next-Gen Memory Systems**"}],["$","meta","6",{"property":"og:url","content":"https://www.yunwei37.com/blog/cxlmemtest"}],["$","meta","7",{"property":"og:site_name","content":"云微的胡思乱想"}],["$","meta","8",{"property":"og:locale","content":"en_US"}],["$","meta","9",{"property":"og:image","content":"https://www.yunwei37.com/static/images/twitter-card.png"}],["$","meta","10",{"property":"og:type","content":"article"}],["$","meta","11",{"property":"article:published_time","content":"2025-06-21T16:00:00.000Z"}],["$","meta","12",{"property":"article:modified_time","content":"2025-06-21T16:00:00.000Z"}],["$","meta","13",{"property":"article:author","content":"Yusheng Zheng (云微)"}],["$","meta","14",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","15",{"name":"twitter:title","content":"**The Modern Memory Testing Arsenal -- A Complete Guide to Benchmarking Tools for Next-Gen Memory Systems**"}],["$","meta","16",{"name":"twitter:image","content":"https://www.yunwei37.com/static/images/twitter-card.png"}]],"error":null,"digest":"$undefined"}
26:"$21:metadata"
